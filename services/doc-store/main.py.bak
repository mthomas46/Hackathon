"""Service: Doc Store

Endpoints:
- POST /documents, POST /documents/enveloped, GET /documents/{id}
- GET /documents/_list, GET /search, GET /documents/quality
- POST /analyses, GET /analyses, GET /style/examples

Dependencies: FastAPI, SQLite, optional Redis pub/sub, shared middlewares, ServiceClients (callers).
"""
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import Optional, Dict, Any, List
from datetime import datetime, timezone
import hashlib
import json
import os
import sqlite3

try:
    import redis.asyncio as aioredis  # type: ignore
except Exception:
    aioredis = None

from services.shared.utils import stable_hash  # type: ignore
from services.shared.config import load_yaml_config  # type: ignore
from services.shared.envelopes import DocumentEnvelope, validate_envelope  # type: ignore
from services.shared.middleware import RequestIdMiddleware, RequestMetricsMiddleware  # type: ignore
from services.shared.utils import attach_self_register  # type: ignore
from services.shared.health import HealthManager, create_health_endpoint  # type: ignore
from services.shared.responses import SuccessResponse, ErrorResponse, create_success_response  # type: ignore
from services.shared.error_handling import handle_service_exception, raise_not_found  # type: ignore
from services.shared.constants_new import ServiceNames, ErrorCodes, Limits  # type: ignore
from services.shared.utilities import utc_now, generate_id, clean_string  # type: ignore
from services.doc_store.logic import compute_quality_flags  # type: ignore


_cfg = load_yaml_config("services/doc-store/config.yaml")
DB_PATH = os.environ.get("DOCSTORE_DB", _cfg.get("db_path", "services/doc-store/db.sqlite3"))


# ============================================================================
# CLEANED UP UTILITY FUNCTIONS - Using Shared Utilities
# ============================================================================

# REMOVED: def utc_now().isoformat() -> str:
#     return datetime.now(timezone.utc).isoformat()
# REPLACED WITH: utc_now() from shared utilities
# Usage: utc_now().isoformat()

# REMOVED: def _connect() -> sqlite3.Connection:
#     os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)
#     conn = sqlite3.connect(DB_PATH)
#     conn.execute("PRAGMA journal_mode=WAL;")
#     return conn
# REPLACED WITH: ensure_directory() from shared utilities
# Usage: ensure_directory(os.path.dirname(DB_PATH))


def _init_db() -> None:
    # CLEANED UP: Using shared utilities for directory creation and database connection
    from services.shared.utilities import ensure_directory

    ensure_directory(os.path.dirname(DB_PATH))
    conn = sqlite3.connect(DB_PATH)
    conn.execute("PRAGMA journal_mode=WAL;")
    try:
        conn.execute(
            """
            CREATE TABLE IF NOT EXISTS documents (
              id TEXT PRIMARY KEY,
              content TEXT,
              content_hash TEXT,
              metadata TEXT,
              created_at TEXT
            )
            """
        )
        conn.execute(
            """
            CREATE TABLE IF NOT EXISTS analyses (
              id TEXT PRIMARY KEY,
              document_id TEXT,
              analyzer TEXT,
              model TEXT,
              prompt_hash TEXT,
              result TEXT,
              score REAL,
              metadata TEXT,
              created_at TEXT,
              FOREIGN KEY(document_id) REFERENCES documents(id)
            )
            """
        )
        conn.execute(
            """
            CREATE TABLE IF NOT EXISTS ensembles (
              id TEXT PRIMARY KEY,
              document_id TEXT,
              config TEXT,
              results TEXT,
              analysis TEXT,
              created_at TEXT,
              FOREIGN KEY(document_id) REFERENCES documents(id)
            )
            """
        )
        conn.execute(
            """
            CREATE TABLE IF NOT EXISTS style_examples (
              id TEXT PRIMARY KEY,
              document_id TEXT,
              language TEXT,
              title TEXT,
              tags TEXT,
              created_at TEXT,
              FOREIGN KEY(document_id) REFERENCES documents(id)
            )
            """
        )
        conn.execute("CREATE INDEX IF NOT EXISTS idx_documents_content_hash ON documents(content_hash)")
        conn.execute("CREATE INDEX IF NOT EXISTS idx_analyses_document_id ON analyses(document_id)")
        conn.execute("CREATE INDEX IF NOT EXISTS idx_analyses_prompt_hash ON analyses(prompt_hash)")
        conn.execute("CREATE INDEX IF NOT EXISTS idx_analyses_created_at ON analyses(created_at)")
        conn.execute("CREATE INDEX IF NOT EXISTS idx_style_examples_language ON style_examples(language)")
        # Optional FTS for search (best-effort)
        try:
            conn.execute(
                """
                CREATE VIRTUAL TABLE IF NOT EXISTS documents_fts USING fts5(
                  id UNINDEXED,
                  title,
                  content,
                  tags
                )
                """
            )
        except Exception:
            pass
        conn.commit()
    finally:
        conn.close()


app = FastAPI(title="Doc Store", version="0.1.0")
app.add_middleware(RequestIdMiddleware)
app.add_middleware(RequestMetricsMiddleware, service_name="doc-store")
attach_self_register(app, "doc-store")
_init_db()
from services.shared.errors import install_error_handlers  # type: ignore
install_error_handlers(app)
# ============================================================================
# CLEANED UP HEALTH ENDPOINT - Using Standardized Health System
# ============================================================================

# Create health manager for this service
health_manager = HealthManager("doc-store", "1.0.0")

# Register standardized health endpoints
register_health_endpoints(app, "doc-store", "1.0.0")

# OLD WAY (removed - was 8 lines of duplicate code):
# @app.get("/health")
# async def health():
#     return {
#         "service": "doc-store",
#         "status": "healthy",
#         "version": "1.0.0",
#         "timestamp": "2024-01-15T10:30:00Z"
#     }

# NEW WAY (1 line replacement using shared health system):
# register_health_endpoints(app, "doc-store", "1.0.0") - Done above!


# ============================================================================
# CLEANED UP RESPONSE FORMATTING - Using Standardized Response Models
# ============================================================================

@app.get("/info")
async def info():
    """Service information endpoint."""
    return create_success_response(
        "Service information retrieved",
        {"service": ServiceNames.DOC_STORE, "version": app.version}
    )  # CLEANED UP: Using standardized success response

@app.get("/config/effective")
async def config_effective():
    """Effective configuration endpoint."""
    # In real use would include actual configuration data
    return create_success_response(
        "Configuration retrieved",
        {"db_path": DB_PATH, "middleware_enabled": True}
    )  # CLEANED UP: Using standardized success response with real config data

@app.get("/metrics")
async def metrics():
    """Service metrics endpoint."""
    return create_success_response(
        "Metrics retrieved",
        {"service": ServiceNames.DOC_STORE, "routes": len(app.routes), "active_connections": 0}
    )  # CLEANED UP: Using standardized success response


class PutDocumentRequest(BaseModel):
    id: Optional[str] = None
    content: str
    content_hash: Optional[str] = None
    metadata: Optional[Dict[str, Any]] = None
    correlation_id: Optional[str] = None


@app.post("/documents")
async def put_document(req: PutDocumentRequest):
    doc_id = req.id or f"doc:{stable_hash(req.content)[:12]}"
    chash = req.content_hash or stable_hash(req.content)
    # augment metadata with content_length
    meta_obj = req.metadata or {}
    try:
        if isinstance(meta_obj, dict):
            meta_obj.setdefault("content_length", len(req.content or ""))
    except Exception:
        pass
    meta_json = json.dumps(meta_obj)

    # CLEANED UP: Using shared utilities for database operations
    from services.shared.utilities import ensure_directory

    ensure_directory(os.path.dirname(DB_PATH))
    conn = sqlite3.connect(DB_PATH)
    conn.execute("PRAGMA journal_mode=WAL;")

    try:
        conn.execute(
            "INSERT OR REPLACE INTO documents (id, content, content_hash, metadata, created_at) VALUES (?,?,?,?,?)",
            (doc_id, req.content, chash, meta_json, utc_now().isoformat()),  # CLEANED UP: Using shared utc_now()
        )
        # If style example, index it
        try:
            meta = req.metadata or {}
            if isinstance(meta, dict) and meta.get("type") == "style_example":
                language = (meta.get("language") or "").lower()
                title = meta.get("title") or None
                tags = ",".join(meta.get("tags") or []) if isinstance(meta.get("tags"), list) else None
                conn.execute(
                    "INSERT OR REPLACE INTO style_examples (id, document_id, language, title, tags, created_at) VALUES (?,?,?,?,?,?)",
                    (f"style:{language}:{chash[:12]}", doc_id, language, title, tags, utc_now().isoformat()),
                )
        except Exception:
            pass
        conn.commit()
    finally:
        conn.close()
    # Update FTS index
    try:
        title = (req.metadata or {}).get("title") if isinstance(req.metadata, dict) else None
        tags = []
        if isinstance(req.metadata, dict) and isinstance(req.metadata.get("tags"), list):
            tags = req.metadata.get("tags") or []
        _fts_upsert(doc_id, title or None, req.content or "", ",".join(tags))
    except Exception:
        pass
    # Validate envelope shape for downstream consumers
    env = DocumentEnvelope(
        id=doc_id,
        version=None,
        correlation_id=req.correlation_id,
        source_refs=[],
        content_hash=chash,
        document={"id": doc_id, "content_hash": chash, "metadata": meta_obj or {}},
    )
    # Best-effort publish
    if aioredis:
        try:
            host = os.environ.get("REDIS_HOST")
            if host:
                client = aioredis.from_url(f"redis://{host}")
                await client.publish("docs.stored", env.model_dump_json())
                await client.aclose()
        except Exception:
            pass
    return {"id": doc_id, "content_hash": chash}


@app.post("/documents/enveloped")
async def put_document_enveloped(env: DocumentEnvelope):
    inner = env.document or {}
    content = inner.get("content") or ""
    provided_id = env.id or inner.get("id")
    doc_id = provided_id or f"doc:{stable_hash(content)[:12]}"
    chash = env.content_hash or inner.get("content_hash") or stable_hash(content)
    # augment metadata with content_length
    meta_obj = inner.get("metadata") or {}
    try:
        if isinstance(meta_obj, dict):
            meta_obj.setdefault("content_length", len(content or ""))
    except Exception:
        pass
    meta_json = json.dumps(meta_obj)
    conn = _connect()
    try:
        conn.execute(
            "INSERT OR REPLACE INTO documents (id, content, content_hash, metadata, created_at) VALUES (?,?,?,?,?)",
            (doc_id, content, chash, meta_json, utc_now().isoformat()),
        )
        # If style example, index it
        try:
            meta = inner.get("metadata") or {}
            if isinstance(meta, dict) and meta.get("type") == "style_example":
                language = (meta.get("language") or "").lower()
                title = meta.get("title") or None
                tags = ",".join(meta.get("tags") or []) if isinstance(meta.get("tags"), list) else None
                conn.execute(
                    "INSERT OR REPLACE INTO style_examples (id, document_id, language, title, tags, created_at) VALUES (?,?,?,?,?,?)",
                    (f"style:{language}:{chash[:12]}", doc_id, language, title, tags, utc_now().isoformat()),
                )
        except Exception:
            pass
        conn.commit()
    finally:
        conn.close()
    # Update FTS index
    try:
        meta = inner.get("metadata") or {}
        title = meta.get("title") if isinstance(meta, dict) else None
        tags = []
        if isinstance(meta, dict) and isinstance(meta.get("tags"), list):
            tags = meta.get("tags") or []
        _fts_upsert(doc_id, title or None, content or "", ",".join(tags))
    except Exception:
        pass
    # Best-effort publish with normalized envelope
    if aioredis:
        try:
            host = os.environ.get("REDIS_HOST")
            if host:
                client = aioredis.from_url(f"redis://{host}")
                env_out = DocumentEnvelope(
                    id=doc_id,
                    version=env.version,
                    correlation_id=env.correlation_id,
                    source_refs=env.source_refs,
                    content_hash=chash,
                    document={"id": doc_id, "content": content, "content_hash": chash, "metadata": inner.get("metadata") or {}},
                )
                await client.publish("docs.stored", env_out.model_dump_json())
                await client.aclose()
        except Exception:
            pass
    return {"id": doc_id, "content_hash": chash}


class GetDocumentResponse(BaseModel):
    id: str
    content: str
    content_hash: str
    metadata: Dict[str, Any]
    created_at: str


@app.get("/documents/{doc_id}", response_model=GetDocumentResponse)
async def get_document(doc_id: str):
    conn = _connect()
    try:
        cur = conn.execute("SELECT id, content, content_hash, metadata, created_at FROM documents WHERE id=?", (doc_id,))
        row = cur.fetchone()
    finally:
        conn.close()
    if not row:
        raise_not_found("document", doc_id)  # CLEANED UP: Using standardized error handling
    meta = {}
    try:
        meta = json.loads(row[3] or "{}")
    except Exception:
        meta = {}
    return GetDocumentResponse(id=row[0], content=row[1] or "", content_hash=row[2] or "", metadata=meta, created_at=row[4] or "")


class PutAnalysisRequest(BaseModel):
    document_id: Optional[str] = None
    content: Optional[str] = None
    analyzer: Optional[str] = None
    model: Optional[str] = None
    prompt: Optional[str] = None
    result: Dict[str, Any]
    score: Optional[float] = None
    metadata: Optional[Dict[str, Any]] = None


@app.post("/analyses")
async def put_analysis(req: PutAnalysisRequest):
    if not req.document_id and not req.content:
        raise ValidationException(
            "Provide document_id or content",
            {"document_id": ["Required if content not provided"], "content": ["Required if document_id not provided"]}
        )  # CLEANED UP: Using standardized validation error handling
    doc_id = req.document_id
    if not doc_id:
        # Store content as a document first
        dreq = PutDocumentRequest(content=req.content or "")
        await put_document(dreq)
        doc_id = dreq.id or f"doc:{stable_hash(dreq.content)[:12]}"
    prompt_hash = stable_hash(req.prompt or "")
    analysis_id = f"an:{stable_hash((doc_id or '') + (req.analyzer or '') + (req.model or '') + prompt_hash)[:12]}"
    conn = _connect()
    try:
        conn.execute(
            "INSERT OR REPLACE INTO analyses (id, document_id, analyzer, model, prompt_hash, result, score, metadata, created_at) VALUES (?,?,?,?,?,?,?,?,?)",
            (
                analysis_id,
                doc_id,
                req.analyzer,
                req.model,
                prompt_hash,
                json.dumps(req.result or {}),
                req.score if req.score is not None else None,
                json.dumps(req.metadata or {}),
                utc_now().isoformat(),
            ),
        )
        conn.commit()
    finally:
        conn.close()
    return {"id": analysis_id, "document_id": doc_id}


class ListAnalysesResponse(BaseModel):
    items: List[Dict[str, Any]]


@app.get("/analyses", response_model=ListAnalysesResponse)
async def list_analyses(document_id: Optional[str] = None):
    conn = _connect()
    try:
        if document_id:
            cur = conn.execute("SELECT id, document_id, analyzer, model, prompt_hash, result, score, metadata, created_at FROM analyses WHERE document_id=? ORDER BY created_at DESC", (document_id,))
        else:
            cur = conn.execute("SELECT id, document_id, analyzer, model, prompt_hash, result, score, metadata, created_at FROM analyses ORDER BY created_at DESC LIMIT 100")
        rows = cur.fetchall()
    finally:
        conn.close()
    items: List[Dict[str, Any]] = []
    for r in rows:
        try:
            items.append(
                {
                    "id": r[0],
                    "document_id": r[1],
                    "analyzer": r[2],
                    "model": r[3],
                    "prompt_hash": r[4],
                    "result": json.loads(r[5] or "{}"),
                    "score": r[6],
                    "metadata": json.loads(r[7] or "{}"),
                    "created_at": r[8],
                }
            )
        except Exception:
            continue
    return ListAnalysesResponse(items=items)


class StyleExamplesResponse(BaseModel):
    items: List[Dict[str, Any]]


@app.get("/style/examples", response_model=StyleExamplesResponse)
async def list_style_examples(language: Optional[str] = None):
    conn = _connect()
    try:
        if language:
            cur = conn.execute(
                "SELECT s.language, s.title, s.tags, d.content, d.metadata FROM style_examples s JOIN documents d ON s.document_id=d.id WHERE s.language=? ORDER BY s.created_at DESC",
                (language.lower(),),
            )
        else:
            cur = conn.execute(
                "SELECT s.language, COUNT(1) as cnt FROM style_examples s GROUP BY s.language ORDER BY cnt DESC",
            )
        rows = cur.fetchall()
    finally:
        conn.close()
    items: List[Dict[str, Any]] = []
    if language:
        for r in rows:
            try:
                meta = json.loads(r[4] or "{}")
            except Exception:
                meta = {}
            items.append({
                "language": r[0],
                "title": r[1],
                "tags": (r[2] or "").split(",") if r[2] else [],
                "snippet": r[3],
                "metadata": meta,
            })
    else:
        for r in rows:
            items.append({"language": r[0], "count": r[1]})
    return StyleExamplesResponse(items=items)


class ListDocumentsResponse(BaseModel):
    items: List[Dict[str, Any]]


@app.get("/documents/_list", response_model=ListDocumentsResponse)
async def list_documents(limit: int = 500):
    """List recent documents with metadata for reporting correlation."""
    conn = _connect()
    try:
        cur = conn.execute(
            "SELECT id, content_hash, metadata, created_at FROM documents ORDER BY created_at DESC LIMIT ?",
            (max(1, min(limit, 2000)),),
        )
        rows = cur.fetchall()
    finally:
        conn.close()
    items: List[Dict[str, Any]] = []
    for r in rows:
        try:
            meta = json.loads(r[2] or "{}")
        except Exception:
            meta = {}
        items.append({
            "id": r[0],
            "content_hash": r[1] or "",
            "metadata": meta,
            "created_at": r[3] or "",
        })
    return ListDocumentsResponse(items=items)


def _fts_upsert(doc_id: str, title: Optional[str], content: str, tags: Optional[str]) -> None:
    """Best-effort upsert into FTS index."""
    try:
        conn = _connect()
        try:
            conn.execute("DELETE FROM documents_fts WHERE id=?", (doc_id,))
            conn.execute(
                "INSERT INTO documents_fts (id, title, content, tags) VALUES (?,?,?,?)",
                (doc_id, title or "", content or "", tags or ""),
            )
            conn.commit()
        finally:
            conn.close()
    except Exception:
        return


class SearchResponse(BaseModel):
    items: List[Dict[str, Any]]


@app.get("/search", response_model=SearchResponse)
async def search(q: str, limit: int = 20):
    """Full-text search over documents (best-effort FTS)."""
    items: List[Dict[str, Any]] = []
    use_semantic = False
    try:
        conn = _connect()
        try:
            cur = conn.execute("SELECT id FROM documents_fts WHERE documents_fts MATCH ? LIMIT ?", (q, max(1, min(limit, 100)),))
            rows = cur.fetchall()
        finally:
            conn.close()
        ids = [r[0] for r in rows]
        for doc_id in ids:
            try:
                items.append(await get_document(doc_id))
            except Exception:
                continue
        if not items:
            use_semantic = True
    except Exception:
        use_semantic = True
    # Semantic fallback (stub): keyword containment and simple scoring
    if use_semantic:
        ql = (q or "").lower().split()
        try:
            conn = _connect()
            try:
                cur = conn.execute("SELECT id, content, metadata FROM documents ORDER BY created_at DESC LIMIT 500")
                rows = cur.fetchall()
            finally:
                conn.close()
            scored: List[tuple[int, str]] = []
            for r in rows:
                doc_id = r[0]
                content = (r[1] or "").lower()
                meta = r[2] or ""
                text = content + " " + (meta.lower() if isinstance(meta, str) else "")
                score = sum(1 for tok in ql if tok in text)
                if score > 0:
                    scored.append((score, doc_id))
            for _, doc_id in sorted(scored, key=lambda x: x[0], reverse=True)[: max(1, min(limit, 50))]:
                try:
                    items.append(await get_document(doc_id))
                except Exception:
                    continue
        except Exception:
            items = []
    # get_document returns Pydantic model; ensure plain dicts
    norm_items: List[Dict[str, Any]] = []
    for it in items:
        if hasattr(it, "model_dump"):
            norm_items.append(it.model_dump())
        else:
            norm_items.append(it)  # type: ignore
    return SearchResponse(items=norm_items)


class QualityItem(BaseModel):
    id: str
    created_at: str
    content_hash: str
    stale_days: int
    flags: List[str]
    metadata: Dict[str, Any]
    importance_score: float | None = None
    # optional backlinks count if provided in metadata


class QualityItemWithBadges(QualityItem):
    badges: List[str] = []


class QualityResponse(BaseModel):
    items: List[QualityItemWithBadges]


@app.get("/documents/quality", response_model=QualityResponse)
async def documents_quality(stale_threshold_days: int = 180, min_views: int = 3):
    """Flag potentially stale, redundant, or low-signal documents.

    Heuristics:
    - stale: created_at older than threshold
    - redundant: duplicate content_hash appears multiple times
    - low_views: metadata.views < min_views when provided
    - missing_owner: metadata.owner missing
    """
    conn = _connect()
    try:
        cur = conn.execute("SELECT id, content_hash, metadata, created_at FROM documents ORDER BY created_at DESC LIMIT 1000")
        rows = cur.fetchall()
    finally:
        conn.close()
    from datetime import datetime
    import json as pyjson
    now = datetime.now(timezone.utc)
    out = compute_quality_flags(rows, stale_threshold_days=stale_threshold_days, min_views=min_views)
    items: List[QualityItemWithBadges] = []
    for it in out:
        flags = it.get("flags", []) or []
        badges: List[str] = []
        if "high_importance" in flags:
            badges.append("high_importance")
        if "recently_viewed" in flags:
            badges.append("recently_viewed")
        if "attachments_referenced" in flags:
            badges.append("evidence_attached")
        items.append(QualityItemWithBadges(**it, badges=badges))
    return QualityResponse(items=items)


class MetadataPatch(BaseModel):
    updates: Dict[str, Any]


@app.patch("/documents/{doc_id}/metadata")
async def patch_document_metadata(doc_id: str, req: MetadataPatch):
    conn = _connect()
    try:
        cur = conn.execute("SELECT metadata FROM documents WHERE id=?", (doc_id,))
        row = cur.fetchone()
        meta = {}
        if row and row[0]:
            try:
                meta = json.loads(row[0])
            except Exception:
                meta = {}
        if isinstance(meta, dict):
            meta.update(req.updates or {})
        else:
            meta = req.updates or {}
        conn.execute("UPDATE documents SET metadata=? WHERE id=?", (json.dumps(meta), doc_id))
        conn.commit()
    finally:
        conn.close()
    return {"id": doc_id, "metadata": meta}


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=5087)


