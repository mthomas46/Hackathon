# LLM Documentation Ecosystem Services

## ðŸ—ï¸ Architecture Overview

The LLM Documentation Ecosystem is a comprehensive platform for intelligent prompt engineering, documentation generation, and cross-service orchestration:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CLI Service   â”‚    â”‚ Prompt Store    â”‚    â”‚ Interpreter     â”‚    â”‚ Document Store  â”‚
â”‚   (Port 5130)   â”‚â—„â”€â”€â–ºâ”‚   (Port 5110)   â”‚â—„â”€â”€â–ºâ”‚   (Port 5120)   â”‚â—„â”€â”€â–ºâ”‚   (Port 5140)   â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Interactive   â”‚    â”‚ â€¢ AI Analytics  â”‚    â”‚ â€¢ NLP Engine     â”‚    â”‚ â€¢ Doc Storage    â”‚
â”‚ â€¢ Menu System   â”‚    â”‚ â€¢ A/B Testing   â”‚    â”‚ â€¢ Intent Recog   â”‚    â”‚ â€¢ Versioning     â”‚
â”‚ â€¢ Workflow Exec â”‚    â”‚ â€¢ Optimization  â”‚    â”‚ â€¢ Query Parsing  â”‚    â”‚ â€¢ Search         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚                       â”‚
         â”‚                       â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Code Analyzer   â”‚    â”‚  Summarizer     â”‚    â”‚ Notification    â”‚    â”‚  Orchestrator   â”‚
â”‚   (Port 5150)   â”‚    â”‚   Hub (5160)    â”‚    â”‚ Service (5210)   â”‚    â”‚   (Port 5000)   â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Code Analysis â”‚    â”‚ â€¢ Doc Summary   â”‚    â”‚ â€¢ Event Notif    â”‚    â”‚ â€¢ Service Coord â”‚
â”‚ â€¢ AST Parsing   â”‚    â”‚ â€¢ Key Concepts  â”‚    â”‚ â€¢ Webhooks       â”‚    â”‚ â€¢ Load Balance  â”‚
â”‚ â€¢ Complexity    â”‚    â”‚ â€¢ Topic Extract â”‚    â”‚ â€¢ Email/Slack    â”‚    â”‚ â€¢ Health Checks â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸš€ Core Services

### 1. ðŸ¤– Prompt Store Service (`services/prompt_store/`)
[README](./prompt_store/README.md) Â· [Tests](../tests/unit/prompt_store)
**Port: 5110** | **Purpose: Intelligent Prompt Engineering Platform**

#### ðŸ§  Advanced Features:
- âœ… **Full CRUD Operations**: Create, read, update, delete prompts with validation
- âœ… **Version Control**: Complete prompt evolution tracking with change summaries
- âœ… **Lifecycle Management**: Draft â†’ Published â†’ Deprecated â†’ Archived workflow
- âœ… **Semantic Relationships**: Extends, references, alternatives between prompts
- âœ… **A/B Testing Automation**: Automated optimization experiments with traffic splitting
- âœ… **AI-Powered Analytics**: Performance metrics, user satisfaction, cost optimization
- âœ… **Dynamic Orchestration**: Conditional chains and prompt pipelines
- âœ… **Cross-Service Intelligence**: Code-to-prompt and document-driven generation
- âœ… **Quality Assurance**: Automated testing, linting, bias detection
- âœ… **Real-time Notifications**: Webhook + notification service integration
- âœ… **Bulk Operations**: Batch processing for efficiency

#### ðŸŽ¯ Key Endpoints (28+ total):
```bash
# Core Operations
GET    /health                    # Health check
POST   /api/v1/prompts            # Create prompt
GET    /api/v1/prompts            # List prompts
GET    /api/v1/prompts/{id}       # Get specific prompt
PUT    /api/v1/prompts/{id}       # Update prompt

# Analytics & Intelligence
GET    /api/v1/analytics/dashboard    # Performance dashboard
POST   /api/v1/analytics/usage        # Record usage metrics
POST   /api/v1/analytics/satisfaction # User feedback

# A/B Testing & Optimization
POST   /api/v1/optimization/ab-tests       # Create A/B test
GET    /api/v1/optimization/ab-tests/{id}/results # Test results
POST   /api/v1/optimization/variations     # Generate variations

# Orchestration & Workflows
POST   /api/v1/orchestration/chains        # Create conditional chains
POST   /api/v1/orchestration/pipelines     # Create prompt pipelines
POST   /api/v1/orchestration/prompts/select # Optimal prompt selection

# Cross-Service Intelligence
POST   /api/v1/intelligence/code/generate      # Generate from code
POST   /api/v1/intelligence/document/generate  # Generate from docs
POST   /api/v1/intelligence/service/generate   # Service integration prompts

# Quality Assurance
POST   /api/v1/validation/lint         # Lint prompts
POST   /api/v1/validation/bias-detect  # Detect bias
POST   /api/v1/validation/test-suites  # Create test suites
```

#### ðŸ“Š Advanced Capabilities:
- **Performance Analytics**: Success rates, response times, token usage, cost tracking
- **User Satisfaction**: Rating system with AI-assisted quality assessment
- **Cost Optimization**: Monitor and optimize LLM API usage across services
- **Bias Detection**: Pattern matching and LLM-based bias analysis
- **Automated Testing**: Comprehensive test suites for prompt validation
- **Evolution Tracking**: Monitor prompt improvements over time
- **Context-Aware Selection**: Intelligent prompt recommendation engine

#### Usage Examples:
```bash
# Create a prompt
curl -X POST http://localhost:5110/prompts \
  -H "Content-Type: application/json" \
  -d '{
    "name": "code_review",
    "category": "code_analysis", 
    "content": "Review this code: {code}",
    "variables": ["code"]
  }'

# Get prompt with variables filled
curl "http://localhost:5110/prompts/search/code_analysis/code_review?code=print('hello')"

# Migrate from YAML
curl -X POST http://localhost:5110/migrate
```

---

### 2. ðŸ“„ Document Store Service (`services/doc_store/`)
[README](./doc_store/README.md) Â· [Tests](../tests/unit/doc_store)
**Port: 5140** | **Purpose: Advanced document storage and management**

#### Features:
- âœ… **Document CRUD**: Full create, read, update operations
- âœ… **Version Control**: Track document evolution
- âœ… **Content Hashing**: Duplicate detection and integrity
- âœ… **Metadata Management**: Rich metadata with JSON support
- âœ… **Correlation Tracking**: Link documents to related entities
- âœ… **Search & Filtering**: Full-text search and metadata filtering
- âœ… **Bulk Operations**: Batch document processing
- âœ… **Analytics**: Usage tracking and performance metrics

#### Key Endpoints:
```bash
POST   /api/v1/documents         # Create document
GET    /api/v1/documents         # List documents
GET    /api/v1/documents/{id}    # Get document
PUT    /api/v1/documents/{id}    # Update document
DELETE /api/v1/documents/{id}    # Delete document
GET    /api/v1/search            # Search documents
```

---

### 3. ðŸ” Code Analyzer Service (`services/code-analyzer/`)
[README](./code-analyzer/README.md) Â· [Tests](../tests/unit/code_analyzer)
**Port: 5150** | **Purpose: Static code analysis for prompt generation**

#### Features:
- âœ… **AST Parsing**: Abstract syntax tree analysis
- âœ… **Function/Method Detection**: Extract function signatures and purposes
- âœ… **Class Analysis**: Object-oriented structure analysis
- âœ… **Complexity Metrics**: Cyclomatic complexity calculation
- âœ… **Language Support**: Multiple programming language support
- âœ… **Dependency Analysis**: Import and dependency mapping
- âœ… **Documentation Generation**: Automatic docstring analysis

#### Key Endpoints:
```bash
POST   /analyze                  # Analyze code
GET    /health                   # Health check
```

---

### 4. ðŸ“ Summarizer Hub Service (`services/summarizer-hub/`)
[README](./summarizer-hub/README.md) Â· [Tests](../tests/unit/summarizer_hub)
**Port: 5160** | **Purpose: Document summarization and key concept extraction**

#### Features:
- âœ… **Document Summarization**: Extractive and abstractive summarization
- âœ… **Key Concept Extraction**: Identify main topics and concepts
- âœ… **Topic Modeling**: Uncover latent topics in documents
- âœ… **Sentiment Analysis**: Document sentiment and tone analysis
- âœ… **Language Detection**: Automatic language identification
- âœ… **Readability Scoring**: Assess document complexity
- âœ… **Multi-format Support**: Handle various document formats

#### Key Endpoints:
```bash
POST   /summarize                # Summarize document
GET    /health                   # Health check
```

---

### 5. ðŸ“¢ Notification Service (`services/notification-service/`)
[README](./notification-service/README.md) Â· [Tests](../tests/unit/notification_service)
**Port: 5210** | **Purpose: Centralized notification management**

#### Features:
- âœ… **Multi-channel Support**: Email, Slack, webhooks, SMS
- âœ… **Owner Resolution**: Map owners to notification targets
- âœ… **Deduplication**: Prevent notification spam
- âœ… **Dead Letter Queue**: Handle failed deliveries
- âœ… **Template Support**: Customizable notification templates
- âœ… **Priority Levels**: High, medium, low priority notifications
- âœ… **Retry Logic**: Automatic retry for failed deliveries
- âœ… **Analytics**: Delivery success tracking

#### Key Endpoints:
```bash
POST   /notify                  # Send notification
POST   /owners/update           # Update owner mappings
POST   /owners/resolve          # Resolve owners to targets
GET    /dlq                     # View dead letter queue
GET    /health                  # Health check
```

---

### 6. ðŸŽ¯ Interpreter Service (`services/interpreter/`)
[README](./interpreter/README.md) Â· [Tests](../tests/unit/interpreter)
**Port: 5120** | **Purpose: Natural language processing and intent recognition**

#### Features:
- âœ… **Intent Recognition**: Understand user intentions
- âœ… **Entity Extraction**: Extract structured data from text
- âœ… **Query Parsing**: Convert natural language to structured queries
- âœ… **Multi-intent Support**: Handle complex multi-step requests
- âœ… **Confidence Scoring**: Rate interpretation accuracy
- âœ… **Context Awareness**: Maintain conversation context
- âœ… **Language Support**: Multiple language processing

#### Supported Intents:
```python
{
  "intents": [
    "create_prompt", "get_prompt", "list_prompts",
    "run_analysis", "generate_report", "health_check",
    "ab_test_create", "workflow_execute"
  ]
}
```

---

### 7. ðŸ§ª Analysis Service (`services/analysis-service/`)
[README](./analysis-service/README.md) Â· [Tests](../tests/unit/analysis_service)
**Purpose: Code and documentation analysis**

#### Features:
- âœ… **Code Analysis**: Static analysis for multiple languages
- âœ… **Documentation Consistency**: Check doc alignment
- âœ… **Quality Metrics**: Code quality and documentation scores
- âœ… **Dependency Analysis**: Module and package relationships
- âœ… **Security Scanning**: Basic security vulnerability detection

---

### 8. ðŸŽ® CLI Service (`services/cli/`)
[README](./cli/README.md) Â· [Tests](../tests/unit/cli)
**Port: 5130** | **Purpose: Interactive command-line interface**

#### Enhanced Features:
- âœ… **Interactive Menu System**: User-friendly navigation
- âœ… **Rich Terminal UI**: Beautiful console interface with colors
- âœ… **Workflow Orchestration**: Execute complex workflows
- âœ… **Health Monitoring**: Real-time service status
- âœ… **Advanced Prompt Management**: Full CRUD operations
- âœ… **A/B Testing Interface**: Create and monitor tests
- âœ… **Analytics Dashboard**: CLI-based analytics viewing
- âœ… **Bulk Operations**: Batch processing commands

#### Enhanced Menu Structure:
```
Main Menu:
1. ðŸ¤– Prompt Management
   â”œâ”€â”€ ðŸ“‹ List all prompts
   â”œâ”€â”€ âž• Create new prompt
   â”œâ”€â”€ ðŸ‘ï¸  View prompt details
   â”œâ”€â”€ âœï¸  Update prompt
   â”œâ”€â”€ ðŸ—‘ï¸  Delete prompt
   â””â”€â”€ ðŸ´ Fork prompt
   â””â”€â”€ ðŸ”— Manage relationships

2. ðŸ§ª A/B Testing
   â”œâ”€â”€ ðŸ†• Create new test
   â”œâ”€â”€ ðŸ“Š View test results
   â”œâ”€â”€ ðŸŽ¯ Select prompts for testing
   â””â”€â”€ ðŸ End test and declare winner

3. ðŸ”„ Workflow Orchestration
   â”œâ”€â”€ ðŸ“„ Run document analysis
   â”œâ”€â”€ ðŸ“¥ Trigger ingestion workflow
   â”œâ”€â”€ âœ… Execute consistency check
   â”œâ”€â”€ ðŸ“Š Generate reports
   â””â”€â”€ ðŸ“ˆ View workflow status

4. ðŸ“Š Analytics & Intelligence
   â”œâ”€â”€ ðŸ“ˆ View performance dashboard
   â”œâ”€â”€ ðŸ’° Cost optimization insights
   â”œâ”€â”€ ðŸ‘¥ User satisfaction metrics
   â””â”€â”€ ðŸŽ¯ Usage trends analysis

5. ðŸ”§ Quality Assurance
   â”œâ”€â”€ ðŸ” Lint prompts
   â”œâ”€â”€ âš–ï¸  Detect bias
   â”œâ”€â”€ ðŸ§ª Run test suites
   â””â”€â”€ ðŸ“‹ Create validation rules

6. ðŸŒ Cross-Service Intelligence
   â”œâ”€â”€ ðŸ’» Generate from code analysis
   â”œâ”€â”€ ðŸ“„ Generate from documents
   â”œâ”€â”€ ðŸ”§ Service integration prompts
   â””â”€â”€ ðŸ“Š Effectiveness analysis

7. ðŸ”” Notifications & Monitoring
   â””â”€â”€ ðŸ“¡ Service health check
```

---

### 9. ðŸŽª GitHub MCP (`services/github-mcp/`)
[README](./github-mcp/README.md) Â· [Tests](../tests/unit/github_mcp)
**Purpose: GitHub integration and repository management**

#### Features:
- âœ… **Repository Analysis**: Code and documentation analysis
- âœ… **Issue/PR Management**: GitHub workflow integration
- âœ… **Webhook Processing**: Real-time GitHub event handling
- âœ… **Documentation Sync**: Keep docs aligned with code
- âœ… **Collaboration Tools**: Team workflow support

#### Features:
- âœ… **Intent Recognition**: Understand user intentions from natural language
- âœ… **Entity Extraction**: Extract URLs, emails, file paths, etc.
- âœ… **Workflow Generation**: Convert queries to executable workflows
- âœ… **Multi-intent Support**: Handle complex multi-step requests
- âœ… **Confidence Scoring**: Rate interpretation confidence

#### Supported Intents:
```python
{
  "analyze_document": ["analyze this document", "check consistency"],
  "consistency_check": ["find inconsistencies", "validate consistency"],
  "ingest_github": ["ingest from github", "pull from github repo"],
  "ingest_jira": ["import jira tickets", "sync jira"],
  "ingest_confluence": ["pull from confluence", "sync confluence pages"],
  "create_prompt": ["create a new prompt", "make a prompt"],
  "find_prompt": ["find a prompt", "search for prompts"],
  "generate_report": ["generate a report", "create a report"],
  "show_analytics": ["show analytics", "view analytics"]
}
```

#### Usage Examples:
```bash
# Interpret a query
curl -X POST http://localhost:5120/interpret \
  -H "Content-Type: application/json" \
  -d '{"query": "analyze this document for consistency issues"}'

# Execute interpreted workflow
curl -X POST http://localhost:5120/execute \
  -H "Content-Type: application/json" \
  -d '{"query": "ingest from github repo https://github.com/user/repo"}'
```

---

## ðŸ› ï¸ Quick Start

### 1. Start Services with Docker Compose:
```bash
# Dev stack (active code mounted, runs `python .../main.py`)
docker compose -f docker-compose.dev.yml up -d

# Or start individual services
docker-compose -f docker-compose.services.yml up prompt-store -d
docker-compose -f docker-compose.services.yml up interpreter -d

# Pass secrets safely (examples)
# 1) Use env file (never commit!)
cat > .env.local <<'EOF'
GITHUB_TOKEN=ghp_xxx
AWS_ACCESS_KEY_ID=...
AWS_SECRET_ACCESS_KEY=...
AWS_SESSION_TOKEN=...
BEDROCK_API_KEY=...
EOF
docker compose --env-file .env.local -f docker-compose.dev.yml up -d summarizer-hub source-agent

# 2) Inline env for one-off local runs
GITHUB_TOKEN=ghp_xxx docker compose -f docker-compose.dev.yml up -d source-agent

# 3) Docker secrets (compose v3+; stub)
#   Define `secrets:` in compose and mount into the container; map them to envs in entrypoint.
```

### 2. Migrate Existing Prompts:
```bash
# Migrate from YAML to database
curl -X POST http://localhost:5110/migrate
```

### 3. Test the CLI:
```bash
# Interactive mode
docker exec -it llm-cli python services/cli/main.py interactive

# Or direct commands
docker exec llm-cli python services/cli/main.py health
```

### 4. Test Natural Language Queries:
```bash
# Test interpretation
curl -X POST http://localhost:5120/interpret \
  -H "Content-Type: application/json" \
  -d '{"query": "analyze my documents"}'

# Execute workflow
curl -X POST http://localhost:5120/execute \
  -H "Content-Type: application/json" \
  -d '{"query": "create a summary report"}'
```

---

## ðŸ”§ Configuration

### Environment Variables:
```bash
# Prompt Store
PROMPT_STORE_DB=/app/data/prompt_store.db
PROMPT_STORE_PORT=5110

# Interpreter
INTERPRETER_PORT=5120

# CLI
CLI_VERBOSE=true
```

### Database Schema:
The Prompt Store uses SQLite with the following tables:
- `prompts` - Core prompt data
- `prompt_versions` - Version history
- `ab_tests` - A/B test configurations
- `ab_test_results` - Test results and metrics
- `prompt_usage` - Usage logging
- `prompt_analytics` - Aggregated analytics
- `user_sessions` - User session tracking

---

## ðŸ“Š Integration Examples

### Python Integration:
```python
from services.shared.clients import ServiceClients

clients = ServiceClients()

# Get a prompt
prompt = await clients.get_json("prompt-store/prompts/search/summarization/default?content=test")

# Interpret user query
interpretation = await clients.post_json("interpreter/interpret", {
    "query": "analyze this document"
})

# Execute workflow
result = await clients.post_json("interpreter/execute", {
    "query": "generate a report"
})
```

### CLI Integration:
```bash
# Get prompt
llm-cli get-prompt summarization default --content "my content"

# Health check
llm-cli health

# List prompts
llm-cli list-prompts --category analysis
```

---

## ðŸ” Monitoring & Debugging

### Health Checks:
```bash
# All services
curl http://localhost:5110/health  # Prompt Store
curl http://localhost:5120/health  # Interpreter

# Service-specific health
docker ps  # Container status
docker logs llm-prompt-store  # Service logs
```

### Logs:
```bash
# View service logs
docker-compose -f docker-compose.services.yml logs prompt-store
docker-compose -f docker-compose.services.yml logs interpreter
docker-compose -f docker-compose.services.yml logs cli
```

### Database Access:
```bash
# Access SQLite database
docker exec -it llm-prompt-store sqlite3 /app/data/prompt_store.db

# Run queries
.schema
SELECT name FROM prompts LIMIT 5;
```

---

## ðŸš€ Advanced Features

### A/B Testing Workflow:
```python
# 1. Create test
test = await clients.post_json("prompt-store/ab-tests", {
    "name": "summary_improvement",
    "prompt_a_id": "summary_v1",
    "prompt_b_id": "summary_v2",
    "test_metric": "response_quality"
})

# 2. Get test prompt for user
result = await clients.get_json(f"prompt-store/ab-tests/{test['id']}/select")

# 3. Use selected prompt
prompt = await clients.get_json(f"prompt-store/prompts/{result['prompt_id']}")

# 4. Record results
await clients.post_json(f"prompt-store/ab-tests/{test['id']}/results", {
    "prompt_id": result['prompt_id'],
    "metric_value": 0.85,
    "sample_size": 100
})
```

### Workflow Orchestration:
```python
# Complex multi-step workflow
interpretation = await clients.post_json("interpreter/interpret", {
    "query": "analyze the github repo, check for security issues, and generate a report"
})

# Execute the generated workflow
result = await clients.post_json("interpreter/execute", {
    "query": "analyze the github repo, check for security issues, and generate a report"
})
```

---

## ðŸ“ˆ Benefits Summary

| Feature | Before | After |
|---------|--------|-------|
| **Prompt Management** | Static YAML files | Full CRUD with database |
| **User Interface** | Command line only | Rich interactive CLI |
| **A/B Testing** | Not supported | Built-in framework |
| **Analytics** | None | Comprehensive tracking |
| **NLP Integration** | Manual parsing | Intelligent interpretation |
| **Workflow Execution** | Manual steps | Automated orchestration |
| **Version Control** | Git only | Full version history |
| **Collaboration** | Single user | Multi-user support |

This upgrade transforms the LLM Documentation Ecosystem from a collection of basic services into a sophisticated, user-friendly platform with advanced AI-powered capabilities! ðŸŽ‰âœ¨
