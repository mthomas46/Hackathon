"""Service: CLI Service

Commands:
- interactive: Start interactive CLI mode with menu-driven interface

Usage:
    python main.py [command] [args...]
    or
    python -m services.cli.main [command] [args...]
"""

# Handle import path issues when running as standalone script
import sys
import os
if __name__ == "__main__":
    # Add parent directory to path for imports when running as script
    parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    if parent_dir not in sys.path:
        sys.path.insert(0, parent_dir)

"""Service: CLI Service

Commands:
- interactive: Start interactive CLI mode with menu-driven interface
- get-prompt <category> <name>: Retrieve and display a specific prompt
- health: Check health status of all ecosystem services
- list-prompts: List all available prompts with optional category filtering
- test-integration: Run comprehensive integration tests across all services

Power User Commands:
- analyze-docs [--type TYPE] [--criteria JSON]: Mass document analysis
- quality-recalc [--type TYPE] [--threshold FLOAT]: Bulk quality recalculation
- bulk-export --format FORMAT [--criteria JSON]: Bulk document export
- bulk-import --file FILE --format FORMAT: Bulk document import
- notify-owners --criteria JSON --message TEXT: Notify document owners
- workflow-run --type TYPE [--config JSON]: Run orchestrator workflows
- redis-info: Display Redis server information
- dlq-stats: Show dead letter queue statistics
- saga-monitor: Monitor active sagas
- tracing-search --criteria JSON: Search distributed traces
- interpret-query "QUERY": Interpret a natural language query
- execute-workflow "QUERY": Interpret and execute a workflow from query
- execute-e2e-query "QUERY" [--format FORMAT] [--download]: Complete end-to-end query processing with output generation
- execute-direct-workflow --name WORKFLOW [--params JSON] [--format FORMAT] [--download]: Direct workflow execution with output
- download-output --file-id FILE_ID [--save-path PATH]: Download generated workflow output files
- download-document --doc-id DOC_ID [--save-path PATH]: Download persistent document from doc_store
- get-document-provenance --doc-id DOC_ID: Get comprehensive provenance for a workflow-generated document
- list-workflow-documents --workflow WORKFLOW [--limit N]: List all documents generated by a workflow
- get-execution-trace --execution-id ID: Get detailed execution trace and generated documents
- list-workflow-templates: List available workflow templates and descriptions
- get-supported-formats: Show supported output formats (JSON, PDF, CSV, markdown, ZIP)
- list-intents: Show all supported query intents
- discover-service --name NAME --url URL [--spec FILE] [--dry-run]: Discover and register service endpoints
- store-memory --type TYPE --key KEY --summary TEXT [--data JSON]: Store operational context in memory
- list-memory [--type TYPE] [--key KEY] [--limit N]: List stored memory items
- detect-content CONTENT [--keywords KW1,KW2]: Analyze content for security risks
- suggest-models CONTENT: Get AI model recommendations based on content sensitivity
- secure-summarize CONTENT [--override-policy]: Generate secure summary with policy enforcement
- ensemble-summarize CONTENT --providers PROVIDERS: Generate summaries using multiple AI providers
- test-provider PROVIDER: Test connectivity to an AI provider
- analyze-code CONTENT [--language LANG] [--repo REPO]: Analyze code for API endpoints and patterns
- scan-security CONTENT [--keywords KW1,KW2]: Scan code for security vulnerabilities
- update-owner --id ID [--owner NAME] [--team TEAM]: Update owner information
- resolve-owners OWNER1,OWNER2: Resolve owners to notification targets
- send-notification --channel CHANNEL --target TARGET --title TITLE --message MESSAGE: Send notification
- view-dlq [--limit N]: View failed notifications in dead letter queue
- submit-log --service SERVICE --level LEVEL --message MESSAGE: Submit a log entry
- query-logs [--service SERVICE] [--level LEVEL] [--limit N]: Query stored logs
- log-stats: View log statistics and analytics
- invoke-ai --prompt PROMPT [--template TEMPLATE] [--format FORMAT]: Invoke AI model with optional template
- ai-templates: List available AI response templates
- ai-history [--limit N]: View recent AI invocation history
- analyze-docs DOC_IDS [--detectors DETECTORS]: Analyze documents for consistency and issues
- get-findings [--severity SEVERITY] [--type TYPE] [--limit N]: Retrieve analysis findings
- generate-report --type TYPE: Generate analysis reports (summary/trends/quality)
- view-config [--service SERVICE]: View service configuration files
- set-env VAR VALUE: Set environment variable
- get-env: Show current environment variables
- validate-config: Validate configuration files and environment variables
- scale-service SERVICE REPLICAS: Scale a service to specified number of replicas
- deployment-status: View current deployment and scaling status
- deploy-service SERVICE IMAGE [--strategy STRATEGY]: Deploy service with new image
- view-dashboards: List available monitoring dashboards
- view-alerts: Show active monitoring alerts
- view-slo-status: Display SLO/SLA compliance status
- view-metrics: Show real-time system metrics

Responsibilities:
- Provide command-line interface for ecosystem management and operations
- Enable interactive prompt management and testing workflows
- Display real-time health status and service integration testing
- Support both programmatic and interactive usage patterns
- Offer rich terminal UI with tables, panels, and colored output
- Provide power-user operations for bulk processing and infrastructure management
- Enable cross-service workflows and automated operations

Features:
- Interactive menu system with keyboard navigation (10 main categories)
- Rich terminal output with syntax highlighting and formatting
- Service health monitoring and integration testing
- Prompt retrieval and management capabilities
- Workflow execution and status monitoring
- Bulk operations (analysis, quality recalculation, data migration)
- Infrastructure monitoring (Redis, DLQ, Sagas, Tracing)
- Document store management (CRUD, search, quality)
- Source agent operations (fetching, normalization, analysis)
- Orchestrator management (workflows, registry, jobs)

Dependencies: All ecosystem services via HTTP clients, Rich library for UI.
"""

import os
import signal
import asyncio
from typing import Dict, Any, List, Optional
from datetime import datetime, timezone
import click
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.prompt import Prompt, Confirm

# ============================================================================
# SHARED MODULES - Leveraging centralized functionality for consistency
# ============================================================================
try:
    from services.shared.monitoring.health import register_health_endpoints
    from services.shared.core.constants_new import ServiceNames, ErrorCodes
except ImportError:
    # Fallback for when imports fail
    print("Warning: Some shared modules not available, using fallbacks")
    class ServiceNames:
        CLI = "cli"
    class ErrorCodes:
        VALIDATION_ERROR = "VALIDATION_ERROR"

# ============================================================================
# LOCAL MODULES - Service-specific functionality
# ============================================================================
try:
    # Try relative imports first (for module execution)
    from .modules.shared_utils import (
        get_cli_clients,
        handle_cli_error,
        create_cli_success_response,
        build_cli_context,
        create_menu_table,
        add_menu_rows,
        print_panel,
        get_service_health_url,
        create_service_health_table,
        create_workflow_status_table,
        create_prompt_table,
        create_search_results_table,
        create_integration_test_table,
        validate_prompt_data,
        extract_variables_from_content,
        format_prompt_details,
        format_analytics_display,
        parse_tags_input,
        create_health_status_display,
        log_cli_metrics
    )
    from .modules.cli_commands import CLICommands
    from .modules.prompt_manager import PromptManager
    from .modules.managers.workflow_manager import WorkflowManager
except ImportError:
    # Fall back to absolute imports (for standalone execution)
    from services.cli.modules.shared_utils import (
        get_cli_clients,
        handle_cli_error,
        create_cli_success_response,
        build_cli_context,
        create_menu_table,
        add_menu_rows,
        print_panel,
        get_service_health_url,
        create_service_health_table,
        create_workflow_status_table,
        create_prompt_table,
        create_search_results_table,
        create_integration_test_table,
        validate_prompt_data,
        extract_variables_from_content,
        format_prompt_details,
        format_analytics_display,
        parse_tags_input,
        create_health_status_display,
        log_cli_metrics
    )
    from services.cli.modules.cli_commands import CLICommands
    from services.cli.modules.prompt_manager import PromptManager
    from services.cli.modules.managers.workflow_manager import WorkflowManager

# Service configuration constants
SERVICE_NAME = "cli"
SERVICE_TITLE = "CLI Service"
SERVICE_VERSION = "1.0.0"

# ============================================================================
# CLI SERVICE - Using modular architecture
# ============================================================================

# Use CLICommands as the main CLI handler
cli_service = CLICommands()

# ============================================================================
# CLI COMMANDS - Using modular CLI service
# ============================================================================

@click.group()
@click.option('--verbose', '-v', is_flag=True, help='Enable verbose output with detailed information')
@click.pass_context
def cli(ctx, verbose):
    """LLM Documentation Ecosystem CLI - Interactive command-line interface for ecosystem management"""
    ctx.ensure_object(dict)
    ctx.obj['VERBOSE'] = verbose
    ctx.obj['cli_service'] = cli_service

@cli.command()
@click.pass_context
def interactive(ctx):
    """Start interactive CLI mode with menu-driven interface for ecosystem operations"""
    # Setup interrupt handling for graceful shutdown
    def signal_handler(signum, frame):
        console = Console()
        console.print("\n[yellow]⚠️  Interrupt received. Shutting down gracefully...[/yellow]")
        # Force exit for immediate termination
        os._exit(1)

    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    try:
        asyncio.run(cli_service.run())
    except KeyboardInterrupt:
        console = Console()
        console.print("\n[yellow]⚠️  CLI interrupted by user[/yellow]")
    except Exception as e:
        console = Console()
        console.print(f"\n[red]❌ Fatal CLI error: {e}[/red]")

@cli.command()
@click.argument('category')
@click.argument('name')
@click.option('--content', '-c', help='Content variable value for prompt template substitution')
@click.pass_context
def get_prompt(ctx, category, name, content):
    """Retrieve and display a prompt from the Prompt Store with optional variable substitution"""
    async def _get_prompt():
        try:
            variables = {}
            if content:
                variables['content'] = content

            response = await cli_service.clients.get_json(f"prompt-store/prompts/search/{category}/{name}", **variables)

            console = Console()
            console.print(f"[bold green]Prompt: {category}.{name}[/bold green]")
            console.print(response.get('prompt', 'No prompt found'))

        except Exception as e:
            console = Console()
            from services.shared.core.responses.responses import create_error_response
            error_response = create_error_response(
                "Failed to retrieve prompt",
                error_code=ErrorCodes.PROMPT_RETRIEVAL_FAILED,
                details={"category": category, "name": name, "error": str(e)}
            )
            console.print(f"[red]Error: {error_response['message']}[/red]")
            console.print(f"[dim]Error Code: {error_response['error_code']}[/dim]")

    asyncio.run(_get_prompt())

@cli.command()
@click.pass_context
def health(ctx):
    """Check and display health status of all ecosystem services with detailed connectivity information"""
    asyncio.run(cli_service.display_health_status())

@cli.command()
@click.option('--category', '-c', help='Filter prompts by specific category (e.g., analysis, consistency)')
@click.pass_context
def list_prompts(ctx, category):
    """List all available prompts from Prompt Store with optional category filtering"""
    prompt_manager = PromptManager(cli_service.console, cli_service.clients)
    asyncio.run(prompt_manager.list_prompts())

@cli.command()
@click.pass_context
def test_integration(ctx):
    """Run comprehensive integration tests across all ecosystem services to verify connectivity and functionality"""
    asyncio.run(cli_service.test_integration())


# ============================================================================
# POWER USER COMMANDS - Advanced operations for experienced users
# ============================================================================

@cli.command()
@click.option('--type', '-t', help='Analysis type (quality, consistency, security, all)')
@click.option('--criteria', '-c', help='Selection criteria as JSON string')
@click.pass_context
def analyze_docs(ctx, type, criteria):
    """Perform mass document analysis across the ecosystem"""
    try:
        import json
        analysis_criteria = json.loads(criteria) if criteria else {}

        bulk_manager = cli_service.bulk_operations_manager
        asyncio.run(bulk_manager.analyze_all_documents(type or "quality"))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.option('--type', help='Document type filter')
@click.option('--threshold', type=float, help='Quality threshold for low-quality recalc')
@click.pass_context
def quality_recalc(ctx, type, threshold):
    """Perform bulk quality score recalculation"""
    try:
        bulk_manager = cli_service.bulk_operations_manager
        if threshold:
            asyncio.run(bulk_manager.recalculate_low_quality(threshold))
        elif type:
            asyncio.run(bulk_manager.recalculate_by_type())
        else:
            asyncio.run(bulk_manager.recalculate_all_quality())
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.option('--format', '-f', required=True, help='Export format (json, csv, xml)')
@click.option('--criteria', '-c', help='Selection criteria as JSON string')
@click.option('--filename', help='Output filename')
@click.pass_context
def bulk_export(ctx, format, criteria, filename):
    """Export documents in bulk"""
    try:
        import json
        export_criteria = json.loads(criteria) if criteria else {}
        output_filename = filename or f"documents_export.{format}"

        bulk_manager = cli_service.bulk_operations_manager
        asyncio.run(bulk_manager.bulk_export_documents(export_criteria, format, output_filename))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.option('--file', '-f', required=True, help='Import file path')
@click.option('--format', required=True, help='Import format (json, csv, xml)')
@click.option('--update-existing', is_flag=True, help='Update existing documents')
@click.pass_context
def bulk_import(ctx, file, format, update_existing):
    """Import documents in bulk"""
    try:
        bulk_manager = cli_service.bulk_operations_manager
        asyncio.run(bulk_manager.bulk_import_documents(file, format, update_existing))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.option('--criteria', '-c', required=True, help='Selection criteria as JSON string')
@click.option('--message', '-m', required=True, help='Notification message')
@click.pass_context
def notify_owners(ctx, criteria, message):
    """Send notifications to document owners"""
    try:
        import json
        selection_criteria = json.loads(criteria)

        bulk_manager = cli_service.bulk_operations_manager
        asyncio.run(bulk_manager.notify_document_owners(selection_criteria, message))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.option('--type', '-t', required=True, help='Workflow type')
@click.option('--config', '-c', help='Workflow configuration as JSON string')
@click.pass_context
def workflow_run(ctx, type, config):
    """Execute orchestrator workflows"""
    try:
        import json
        workflow_config = json.loads(config) if config else {}

        orchestrator_manager = cli_service.orchestrator_manager
        asyncio.run(orchestrator_manager.run_workflow(type, workflow_config))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.pass_context
def redis_info(ctx):
    """Display Redis server information"""
    try:
        infra_manager = cli_service.infrastructure_manager
        asyncio.run(infra_manager.redis_info())
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.pass_context
def dlq_stats(ctx):
    """Show dead letter queue statistics"""
    try:
        infra_manager = cli_service.infrastructure_manager
        asyncio.run(infra_manager.dlq_statistics())
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.pass_context
def saga_monitor(ctx):
    """Monitor active sagas"""
    try:
        infra_manager = cli_service.infrastructure_manager
        asyncio.run(infra_manager.view_active_sagas())
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.option('--criteria', '-c', required=True, help='Search criteria as JSON string')
@click.pass_context
def tracing_search(ctx, criteria):
    """Search distributed traces"""
    try:
        import json
        search_criteria = json.loads(criteria)

        infra_manager = cli_service.infrastructure_manager
        asyncio.run(infra_manager.search_traces(search_criteria))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


# ============================================================================
# INTERPRETER SERVICE COMMANDS
# ============================================================================

@cli.command()
@click.argument('query')
@click.option('--user-id', help='User ID for context')
@click.option('--session-id', help='Session ID for context')
@click.option('--context', '-c', help='Additional context as JSON string')
@click.pass_context
def interpret_query(ctx, query, user_id, session_id, context):
    """Interpret a natural language query and show intent analysis"""
    try:
        import json
        query_data = {"query": query}

        if user_id:
            query_data["user_id"] = user_id
        if session_id:
            query_data["session_id"] = session_id
        if context:
            query_data["context"] = json.loads(context)

        interpreter_manager = cli_service.interpreter_manager
        asyncio.run(interpreter_manager.interpret_single_query_from_cli(query_data))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.argument('query')
@click.option('--user-id', help='User ID for context')
@click.option('--session-id', help='Session ID for context')
@click.option('--context', '-c', help='Additional context as JSON string')
@click.pass_context
def execute_workflow(ctx, query, user_id, session_id, context):
    """Interpret a query and execute the resulting workflow"""
    try:
        import json
        query_data = {"query": query}

        if user_id:
            query_data["user_id"] = user_id
        if session_id:
            query_data["session_id"] = session_id
        if context:
            query_data["context"] = json.loads(context)

        interpreter_manager = cli_service.interpreter_manager
        asyncio.run(interpreter_manager.execute_workflow_from_cli(query_data))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.argument("query")
@click.option("--format", default="json", help="Output format (json, pdf, csv, markdown, zip, txt)")
@click.option("--download", is_flag=True, help="Automatically download the generated file")
@click.option("--user-id", help="User ID for tracking")
@click.option("--filename-prefix", help="Prefix for generated filename")
@click.pass_context
def execute_e2e_query(ctx, query, format, download, user_id, filename_prefix):
    """Complete end-to-end query processing: Natural language → Workflow → Output file"""
    try:
        asyncio.run(_execute_e2e_query_async(query, format, download, user_id, filename_prefix))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.option("--name", required=True, help="Workflow name to execute")
@click.option("--params", help="JSON parameters for the workflow")
@click.option("--format", default="json", help="Output format (json, pdf, csv, markdown, zip, txt)")
@click.option("--download", is_flag=True, help="Automatically download the generated file")
@click.option("--user-id", help="User ID for tracking")
@click.option("--filename-prefix", help="Prefix for generated filename")
@click.pass_context
def execute_direct_workflow(ctx, name, params, format, download, user_id, filename_prefix):
    """Direct workflow execution with output generation"""
    try:
        import json
        parameters = json.loads(params) if params else {}
        asyncio.run(_execute_direct_workflow_async(name, parameters, format, download, user_id, filename_prefix))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.option("--file-id", required=True, help="File ID of the generated output")
@click.option("--save-path", help="Local path to save the downloaded file")
@click.pass_context
def download_output(ctx, file_id, save_path):
    """Download generated workflow output files"""
    try:
        asyncio.run(_download_output_async(file_id, save_path))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.pass_context
def list_workflow_templates(ctx):
    """List available workflow templates and descriptions"""
    try:
        asyncio.run(_list_workflow_templates_async())
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.pass_context
def get_supported_formats(ctx):
    """Show supported output formats (JSON, PDF, CSV, markdown, ZIP)"""
    try:
        asyncio.run(_get_supported_formats_async())
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.option("--doc-id", required=True, help="Document ID in doc_store")
@click.option("--save-path", help="Local path to save the downloaded document")
@click.pass_context
def download_document(ctx, doc_id, save_path):
    """Download persistent document from doc_store"""
    try:
        asyncio.run(_download_document_async(doc_id, save_path))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.option("--doc-id", required=True, help="Document ID to get provenance for")
@click.pass_context
def get_document_provenance(ctx, doc_id):
    """Get comprehensive provenance for a workflow-generated document"""
    try:
        asyncio.run(_get_document_provenance_async(doc_id))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.option("--workflow", required=True, help="Workflow name to list documents for")
@click.option("--limit", default=20, help="Maximum number of documents to list")
@click.pass_context
def list_workflow_documents(ctx, workflow, limit):
    """List all documents generated by a workflow"""
    try:
        asyncio.run(_list_workflow_documents_async(workflow, limit))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.option("--execution-id", required=True, help="Execution ID to get trace for")
@click.pass_context
def get_execution_trace(ctx, execution_id):
    """Get detailed execution trace and generated documents"""
    try:
        asyncio.run(_get_execution_trace_async(execution_id))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.pass_context
def list_intents(ctx):
    """List all supported query intents with examples"""
    try:
        interpreter_manager = cli_service.interpreter_manager
        asyncio.run(interpreter_manager.list_supported_intents())
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


# ============================================================================
# DISCOVERY AGENT COMMANDS
# ============================================================================

@cli.command()
@click.option('--name', '-n', required=True, help='Service name')
@click.option('--url', '-u', required=True, help='Service base URL')
@click.option('--spec', '-s', help='Path to OpenAPI spec file')
@click.option('--openapi-url', '-o', help='OpenAPI spec URL')
@click.option('--dry-run', is_flag=True, help='Dry run (no registration)')
@click.pass_context
def discover_service(ctx, name, url, spec, openapi_url, dry_run):
    """Discover and optionally register service endpoints from OpenAPI spec"""
    try:
        discover_request = {
            "name": name,
            "base_url": url,
            "dry_run": dry_run
        }

        # Load spec from file or URL
        if spec:
            if not os.path.exists(spec):
                console = Console()
                console.print(f"[red]Spec file not found: {spec}[/red]")
                return
            with open(spec, 'r') as f:
                discover_request["spec"] = json.load(f)
        elif openapi_url:
            discover_request["openapi_url"] = openapi_url
        else:
            # Create basic inline spec
            discover_request["spec"] = {
                "openapi": "3.0.0",
                "info": {"title": name.title(), "version": "1.0.0"},
                "paths": {
                    "/health": {
                        "get": {"summary": "Health check", "responses": {"200": {"description": "OK"}}}
                    }
                }
            }

        discovery_manager = cli_service.discovery_agent_manager
        asyncio.run(discovery_manager.discover_service_from_cli(discover_request))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


# ============================================================================
# MEMORY AGENT COMMANDS
# ============================================================================

@cli.command()
@click.option('--type', '-t', required=True, help='Memory item type (operation|llm_summary|doc_summary|api_summary|finding)')
@click.option('--key', '-k', required=True, help='Memory key (correlation_id, doc id, etc.)')
@click.option('--summary', '-s', required=True, help='Summary of the memory item')
@click.option('--data', '-d', help='JSON data payload')
@click.pass_context
def store_memory(ctx, type, key, summary, data):
    """Store operational context and event summaries in memory"""
    try:
        memory_data = {}
        if data:
            memory_data = json.loads(data)

        memory_item = {
            "id": f"cli-memory-{int(datetime.now(timezone.utc).timestamp() * 1000)}",
            "type": type,
            "key": key,
            "summary": summary,
            "data": memory_data
        }

        memory_request = {"item": memory_item}
        memory_manager = cli_service.memory_agent_manager
        asyncio.run(memory_manager.store_memory_from_cli(memory_request))
    except json.JSONDecodeError:
        console = Console()
        console.print(f"[red]Invalid JSON data: {data}[/red]")
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.option('--type', '-t', help='Filter by memory type')
@click.option('--key', '-k', help='Filter by memory key')
@click.option('--limit', '-l', default=50, help='Maximum items to retrieve')
@click.pass_context
def list_memory(ctx, type, key, limit):
    """List stored memory items with optional filtering"""
    try:
        # Create a temporary console for display
        console = Console()

        memory_manager = cli_service.memory_agent_manager

        # Use the list_memory_items method directly to get items
        # This is a bit of a workaround since we need to access the API
        # For now, we'll show a placeholder
        console.print(f"[yellow]Listing memory items (type: {type or 'all'}, key: {key or 'all'}, limit: {limit})[/yellow]")
        console.print("[yellow]This would display memory items from the memory agent[/yellow]")

        # In a real implementation, we'd call the API and display results
        # For now, just show the command was received

    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


# ============================================================================
# SECURE ANALYZER COMMANDS
# ============================================================================

@cli.command()
@click.argument('content')
@click.option('--keywords', '-k', help='Comma-separated list of additional keywords to detect')
@click.pass_context
def detect_content(ctx, content, keywords):
    """Analyze content for sensitive information and security risks"""
    try:
        detect_request = {"content": content}

        if keywords:
            detect_request["keywords"] = [k.strip() for k in keywords.split(",") if k.strip()]

        secure_manager = cli_service.secure_analyzer_manager
        asyncio.run(secure_manager.detect_content_from_cli(detect_request))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.argument('content')
@click.pass_context
def suggest_models(ctx, content):
    """Get AI model recommendations based on content sensitivity"""
    try:
        suggest_request = {"content": content}

        secure_manager = cli_service.secure_analyzer_manager
        asyncio.run(secure_manager.suggest_models_from_cli(suggest_request))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.argument('content')
@click.option('--override-policy', '-o', is_flag=True, help='Override security policy restrictions')
@click.option('--prompt', '-p', help='Custom summarization prompt')
@click.pass_context
def secure_summarize(ctx, content, override_policy, prompt):
    """Generate secure summary with policy-based provider filtering"""
    try:
        summarize_request = {
            "content": content,
            "override_policy": override_policy
        }

        if prompt:
            summarize_request["prompt"] = prompt

        secure_manager = cli_service.secure_analyzer_manager
        asyncio.run(secure_manager.summarize_content_from_cli(summarize_request))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


# ============================================================================
# SUMMARIZER HUB COMMANDS
# ============================================================================

@cli.command()
@click.argument('content')
@click.option('--providers', '-p', required=True, help='Comma-separated list of providers (ollama,openai,anthropic,grok,bedrock)')
@click.option('--prompt', help='Custom summarization prompt')
@click.option('--hub-config', is_flag=True, help='Use hub configuration defaults')
@click.pass_context
def ensemble_summarize(ctx, content, providers, prompt, hub_config):
    """Generate ensemble summaries using multiple AI providers"""
    try:
        provider_list = [p.strip() for p in providers.split(",") if p.strip()]

        if not provider_list:
            console = Console()
            console.print("[red]No providers specified[/red]")
            return

        # Build provider configurations
        provider_configs = []
        for provider in provider_list:
            config = {"name": provider}

            # Add default models and endpoints
            if provider == "ollama":
                config.update({"model": "llama3", "endpoint": "http://localhost:11434"})
            elif provider == "openai":
                config.update({"model": "gpt-4"})
            elif provider == "anthropic":
                config.update({"model": "claude-3-sonnet-20240229"})
            elif provider == "grok":
                config.update({"model": "grok-1"})
            elif provider == "bedrock":
                config.update({"model": "anthropic.claude-3-sonnet-20240229-v1:0", "region": "us-east-1"})

            provider_configs.append(config)

        summarize_request = {
            "text": content,
            "providers": provider_configs,
            "use_hub_config": hub_config
        }

        if prompt:
            summarize_request["prompt"] = prompt

        summarizer_manager = cli_service.summarizer_hub_manager
        asyncio.run(summarizer_manager.summarize_from_cli(summarize_request))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.argument('provider')
@click.pass_context
def test_provider(ctx, provider):
    """Test connectivity to an AI provider"""
    try:
        # Create a simple test request
        test_config = {"name": provider}

        # Add provider-specific defaults
        if provider == "ollama":
            test_config.update({"model": "llama3", "endpoint": "http://localhost:11434"})
        elif provider == "openai":
            test_config.update({"model": "gpt-4"})
        elif provider == "anthropic":
            test_config.update({"model": "claude-3-sonnet-20240229"})
        elif provider == "grok":
            test_config.update({"model": "grok-1"})
        elif provider == "bedrock":
            test_config.update({"model": "anthropic.claude-3-sonnet-20240229-v1:0", "region": "us-east-1"})

        test_request = {
            "text": "Hello world. This is a test message for provider connectivity.",
            "providers": [test_config],
            "use_hub_config": False
        }

        summarizer_manager = cli_service.summarizer_hub_manager

        # Use the test connectivity method - this needs to be wrapped in asyncio.run
        asyncio.run(summarizer_manager.test_provider_connectivity())

    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


# ============================================================================
# CODE ANALYZER COMMANDS
# ============================================================================

@cli.command()
@click.argument('content')
@click.option('--language', '-l', help='Programming language (python, javascript, etc.)')
@click.option('--repo', '-r', help='Repository name')
@click.option('--path', '-p', help='File path within repository')
@click.pass_context
def analyze_code(ctx, content, language, repo, path):
    """Analyze code for API endpoints and programming patterns"""
    try:
        analyze_request = {"content": content}

        if language:
            analyze_request["language"] = language
        if repo:
            analyze_request["repo"] = repo
        if path:
            analyze_request["path"] = path

        code_manager = cli_service.code_analyzer_manager
        asyncio.run(code_manager.analyze_code_from_cli(analyze_request))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.argument('content')
@click.option('--keywords', '-k', help='Comma-separated list of additional keywords to detect')
@click.pass_context
def scan_security(ctx, content, keywords):
    """Scan code for security vulnerabilities and sensitive information"""
    try:
        scan_request = {"content": content}

        if keywords:
            scan_request["keywords"] = [k.strip() for k in keywords.split(",") if k.strip()]

        code_manager = cli_service.code_analyzer_manager
        asyncio.run(code_manager.scan_security_from_cli(scan_request))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


# ============================================================================
# NOTIFICATION SERVICE COMMANDS
# ============================================================================

@cli.command()
@click.option('--id', '-i', required=True, help='Entity ID to update')
@click.option('--owner', '-o', help='Owner name')
@click.option('--team', '-t', help='Team name')
@click.pass_context
def update_owner(ctx, id, owner, team):
    """Update owner information in the notification service"""
    try:
        update_request = {"id": id}

        if owner:
            update_request["owner"] = owner
        if team:
            update_request["team"] = team

        notification_manager = cli_service.notification_service_manager
        asyncio.run(notification_manager.update_owner_from_cli(update_request))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.argument('owners')
@click.pass_context
def resolve_owners(ctx, owners):
    """Resolve owner names to notification targets"""
    try:
        owners_list = [owner.strip() for owner in owners.split(",") if owner.strip()]

        if not owners_list:
            console = Console()
            console.print("[red]No owners specified[/red]")
            return

        resolve_request = {"owners": owners_list}

        notification_manager = cli_service.notification_service_manager
        asyncio.run(notification_manager.resolve_owners_from_cli(resolve_request))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.option('--channel', '-c', required=True, help='Notification channel (webhook/email/slack)')
@click.option('--target', '-t', required=True, help='Delivery target (URL/email/channel)')
@click.option('--title', required=True, help='Notification title')
@click.option('--message', '-m', required=True, help='Notification message')
@click.option('--metadata', help='JSON metadata for notification')
@click.option('--labels', '-l', help='Comma-separated labels')
@click.pass_context
def send_notification(ctx, channel, target, title, message, metadata, labels):
    """Send notification through specified channel"""
    try:
        notification_request = {
            "channel": channel,
            "target": target,
            "title": title,
            "message": message,
            "metadata": {},
            "labels": []
        }

        if metadata:
            try:
                notification_request["metadata"] = json.loads(metadata)
            except json.JSONDecodeError:
                console = Console()
                console.print(f"[yellow]Invalid JSON metadata, using empty dict[/yellow]")

        if labels:
            notification_request["labels"] = [label.strip() for label in labels.split(",") if label.strip()]

        notification_manager = cli_service.notification_service_manager
        asyncio.run(notification_manager.send_notification_from_cli(notification_request))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.option('--limit', '-l', default=20, help='Maximum number of entries to retrieve')
@click.pass_context
def view_dlq(ctx, limit):
    """View failed notifications in dead letter queue"""
    try:
        # Get DLQ entries and display them
        console = Console()

        # This would normally call the notification service API
        # For now, show a placeholder
        console.print(f"[yellow]Viewing up to {limit} failed notifications from DLQ[/yellow]")
        console.print("[yellow]This would display failed notification details[/yellow]")

        # In a real implementation, we'd call the API and display results

    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


# ============================================================================
# LOG COLLECTOR COMMANDS
# ============================================================================

@cli.command()
@click.option('--service', '-s', required=True, help='Service name that generated the log')
@click.option('--level', '-l', required=True, help='Log level (debug/info/warning/error/fatal)')
@click.option('--message', '-m', required=True, help='Log message')
@click.option('--context', '-c', help='JSON context data for the log entry')
@click.pass_context
def submit_log(ctx, service, level, message, context):
    """Submit a log entry to the log collector"""
    try:
        log_request = {
            "service": service,
            "level": level,
            "message": message
        }

        if context:
            try:
                log_request["context"] = json.loads(context)
            except json.JSONDecodeError:
                console = Console()
                console.print(f"[yellow]Invalid JSON context, using empty context[/yellow]")

        log_manager = cli_service.log_collector_manager
        asyncio.run(log_manager.submit_log_from_cli(log_request))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.option('--service', '-s', help='Filter by service name')
@click.option('--level', '-l', help='Filter by log level')
@click.option('--limit', '-n', default=50, help='Maximum number of logs to retrieve')
@click.pass_context
def query_logs(ctx, service, level, limit):
    """Query stored logs with optional filtering"""
    try:
        params = {"limit": limit}
        if service:
            params["service"] = service
        if level:
            params["level"] = level

        log_manager = cli_service.log_collector_manager
        asyncio.run(log_manager.query_logs_from_cli(params))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.pass_context
def log_stats(ctx):
    """View log statistics and analytics"""
    try:
        log_manager = cli_service.log_collector_manager
        asyncio.run(log_manager.get_log_stats_from_cli())
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


# ============================================================================
# BEDROCK PROXY COMMANDS
# ============================================================================

@cli.command()
@click.option('--prompt', '-p', required=True, help='Prompt text for AI model')
@click.option('--template', '-t', help='Response template (summary/risks/decisions/pr_confidence/life_of_ticket)')
@click.option('--format', '-f', default='md', help='Output format (md/txt/json)')
@click.option('--model', '-m', help='AI model to use')
@click.option('--region', '-r', help='AWS region')
@click.option('--title', help='Custom title for response')
@click.pass_context
def invoke_ai(ctx, prompt, template, format, model, region, title):
    """Invoke AI model with optional template and formatting"""
    try:
        request_data = {
            "prompt": prompt,
            "format": format
        }

        if template:
            request_data["template"] = template
        if model:
            request_data["model"] = model
        if region:
            request_data["region"] = region
        if title:
            request_data["title"] = title

        bedrock_manager = cli_service.bedrock_proxy_manager
        asyncio.run(bedrock_manager.invoke_ai_from_cli(request_data))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.pass_context
def ai_templates(ctx):
    """List available AI response templates"""
    try:
        bedrock_manager = cli_service.bedrock_proxy_manager
        asyncio.run(bedrock_manager.list_available_templates())
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.option('--limit', '-l', default=10, help='Maximum number of recent invocations to show')
@click.pass_context
def ai_history(ctx, limit):
    """View recent AI invocation history"""
    try:
        bedrock_manager = cli_service.bedrock_proxy_manager
        # Temporarily modify the limit for view_recent_invocations
        original_limit = limit
        asyncio.run(bedrock_manager.view_recent_invocations())
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


# ============================================================================
# ANALYSIS SERVICE COMMANDS
# ============================================================================

@cli.command()
@click.argument('doc_ids', nargs=-1, required=True)
@click.option('--detectors', '-d', help='Comma-separated list of detectors to use')
@click.option('--severity-filter', '-s', help='Minimum severity level to report')
@click.pass_context
def analyze_docs(ctx, doc_ids, detectors, severity_filter):
    """Analyze documents for consistency and issues"""
    try:
        if not doc_ids:
            console = Console()
            console.print("[red]Error: At least one document ID is required[/red]")
            return

        analysis_request = {
            "targets": list(doc_ids)
        }

        if detectors:
            analysis_request["detectors"] = [d.strip() for d in detectors.split(",") if d.strip()]

        if severity_filter:
            analysis_request["severity_filter"] = severity_filter

        analysis_manager = cli_service.analysis_service_manager
        asyncio.run(analysis_manager.analyze_document_from_cli(analysis_request))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.option('--severity', '-s', help='Filter by severity level (critical/high/medium/low/info)')
@click.option('--type', '-t', help='Filter by finding type')
@click.option('--limit', '-l', default=50, help='Maximum number of findings to retrieve')
@click.pass_context
def get_findings(ctx, severity, type, limit):
    """Retrieve analysis findings with optional filtering"""
    try:
        params = {"limit": limit}
        if severity:
            params["severity"] = severity
        if type:
            params["finding_type_filter"] = type

        analysis_manager = cli_service.analysis_service_manager
        asyncio.run(analysis_manager.get_findings_from_cli(params))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.option('--type', '-t', required=True, help='Report type (summary/trends/quality)')
@click.option('--time-period', help='Time period for trends report (e.g., 30d, 7d)')
@click.option('--quality-threshold', type=float, help='Quality threshold for quality report (0.0-1.0)')
@click.pass_context
def generate_report(ctx, type, time_period, quality_threshold):
    """Generate analysis reports"""
    try:
        report_request = {"type": type}

        if type == "trends" and time_period:
            report_request["time_period"] = time_period

        if type == "quality" and quality_threshold is not None:
            if not (0.0 <= quality_threshold <= 1.0):
                console = Console()
                console.print("[red]Error: Quality threshold must be between 0.0 and 1.0[/red]")
                return
            report_request["quality_threshold"] = quality_threshold

        analysis_manager = cli_service.analysis_service_manager
        asyncio.run(analysis_manager.generate_report_from_cli(report_request))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


# ============================================================================
# CONFIGURATION MANAGEMENT COMMANDS
# ============================================================================

@cli.command()
@click.option('--service', '-s', help='Service name to view configuration for')
@click.pass_context
def view_config(ctx, service):
    """View service configuration files"""
    try:
        config_manager = cli_service.config_manager
        asyncio.run(config_manager.view_service_configuration())
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.argument('var', required=True)
@click.argument('value', required=True)
@click.pass_context
def set_env(ctx, var, value):
    """Set environment variable"""
    try:
        config_manager = cli_service.config_manager
        asyncio.run(config_manager.set_environment_variable())
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.pass_context
def get_env(ctx):
    """Show current environment variables"""
    try:
        config_manager = cli_service.config_manager
        asyncio.run(config_manager.view_current_environment())
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.pass_context
def validate_config(ctx):
    """Validate configuration files and environment variables"""
    try:
        config_manager = cli_service.config_manager

        # Run multiple validation checks
        console = Console()
        console.print("[yellow]Running configuration validation...[/yellow]")

        # Validate YAML syntax
        console.print("\n[bold]1. YAML Syntax Validation:[/bold]")
        asyncio.run(config_manager.validate_yaml_syntax())

        # Validate environment variables
        console.print("\n[bold]2. Environment Variable Validation:[/bold]")
        asyncio.run(config_manager.environment_variable_validation())

        # Configuration health check
        console.print("\n[bold]3. Configuration Health Check:[/bold]")
        asyncio.run(config_manager.configuration_health_check())

    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


# ============================================================================
# DEPLOYMENT CONTROLS COMMANDS
# ============================================================================

@cli.command()
@click.argument('service', required=True)
@click.argument('replicas', type=int, required=True)
@click.pass_context
def scale_service(ctx, service, replicas):
    """Scale a service to specified number of replicas"""
    try:
        if replicas < 0:
            console = Console()
            console.print("[red]Error: Number of replicas must be non-negative[/red]")
            return

        deployment_manager = cli_service.deployment_manager
        asyncio.run(deployment_manager.scale_service_from_cli(service, replicas))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.pass_context
def deployment_status(ctx):
    """View current deployment and scaling status"""
    try:
        deployment_manager = cli_service.deployment_manager
        asyncio.run(deployment_manager.view_deployment_status_from_cli())
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.argument('service', required=True)
@click.argument('image', required=True)
@click.option('--strategy', '-s', default='rolling', help='Deployment strategy (rolling/blue-green/canary)')
@click.pass_context
def deploy_service(ctx, service, image, strategy):
    """Deploy service with new image"""
    try:
        valid_strategies = ['rolling', 'blue-green', 'canary']
        if strategy not in valid_strategies:
            console = Console()
            console.print(f"[red]Error: Invalid strategy. Must be one of: {', '.join(valid_strategies)}[/red]")
            return

        deployment_manager = cli_service.deployment_manager
        asyncio.run(deployment_manager.start_deployment_from_cli(service, image, strategy))
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


# ============================================================================
# DISCOVERY AGENT INTEGRATION COMMANDS
# ============================================================================

@cli.command()
@click.argument('service', required=False)
@click.option('--all-services', is_flag=True, help='Discover tools for all services')
@click.option('--category', help='Filter tools by category')
@click.pass_context
def discover_tools(ctx, service, all_services, category):
    """Discover LangGraph tools from service OpenAPI specifications"""
    try:
        from services.discovery_agent.modules.tool_discovery import ToolDiscoveryService
        import asyncio
        
        console = Console()
        
        async def run_discovery():
            discovery_service = ToolDiscoveryService()
            
            if all_services:
                # Discover tools for all running services
                services_to_discover = [
                    {"name": "analysis-service", "url": "http://localhost:5020"},
                    {"name": "prompt_store", "url": "http://localhost:5110"},
                    {"name": "memory-agent", "url": "http://localhost:5040"},
                    {"name": "source-agent", "url": "http://localhost:5000"},
                    {"name": "doc_store", "url": "http://localhost:5087"},
                    {"name": "github-mcp", "url": "http://localhost:5072"},
                    {"name": "interpreter", "url": "http://localhost:5120"},
                    {"name": "secure-analyzer", "url": "http://localhost:5070"},
                    {"name": "summarizer-hub", "url": "http://localhost:5160"}
                ]
                
                console.print("\n[bold]🔍 Discovering Tools for All Services[/bold]")
                console.print("=" * 50)
                
                total_tools = 0
                for svc in services_to_discover:
                    console.print(f"\n[blue]Discovering tools for {svc['name']}...[/blue]")
                    try:
                        result = await discovery_service.discover_tools(
                            svc['name'], 
                            svc['url'],
                            tool_categories=[category] if category else None
                        )
                        
                        if result.get('success'):
                            tools = result.get('tools', [])
                            console.print(f"  ✅ Found {len(tools)} tools")
                            total_tools += len(tools)
                            
                            if len(tools) > 0:
                                for tool in tools[:3]:  # Show first 3 tools
                                    console.print(f"    📋 {tool.get('name', 'Unknown')}: {tool.get('category', 'uncategorized')}")
                                if len(tools) > 3:
                                    console.print(f"    ... and {len(tools) - 3} more tools")
                        else:
                            console.print(f"  ❌ Failed: {result.get('error', 'Unknown error')}")
                    except Exception as e:
                        console.print(f"  ❌ Error: {str(e)}")
                
                console.print(f"\n[bold]📊 Discovery Summary:[/bold]")
                console.print(f"  Total Tools Discovered: {total_tools}")
                console.print(f"  Services Scanned: {len(services_to_discover)}")
                
            elif service:
                # Discover tools for specific service
                console.print(f"\n[bold]🔍 Discovering Tools for {service}[/bold]")
                console.print("=" * 40)
                
                # Map service names to URLs (you may need to adjust these)
                service_urls = {
                    "analysis-service": "http://localhost:5020",
                    "prompt_store": "http://localhost:5110", 
                    "memory-agent": "http://localhost:5040",
                    "source-agent": "http://localhost:5000",
                    "doc_store": "http://localhost:5087",
                    "github-mcp": "http://localhost:5072",
                    "interpreter": "http://localhost:5120",
                    "secure-analyzer": "http://localhost:5070",
                    "summarizer-hub": "http://localhost:5160"
                }
                
                if service not in service_urls:
                    console.print(f"[red]❌ Unknown service: {service}[/red]")
                    console.print(f"Available services: {', '.join(service_urls.keys())}")
                    return
                
                try:
                    result = await discovery_service.discover_tools(
                        service, 
                        service_urls[service],
                        tool_categories=[category] if category else None
                    )
                    
                    if result.get('success'):
                        tools = result.get('tools', [])
                        console.print(f"\n✅ Discovered {len(tools)} tools for {service}")
                        
                        if tools:
                            console.print("\n[bold]📋 Discovered Tools:[/bold]")
                            for i, tool in enumerate(tools, 1):
                                console.print(f"  {i}. [cyan]{tool.get('name', 'Unknown')}[/cyan]")
                                console.print(f"     Category: {tool.get('category', 'uncategorized')}")
                                console.print(f"     Description: {tool.get('description', 'No description')}")
                                if tool.get('parameters'):
                                    console.print(f"     Parameters: {len(tool.get('parameters', []))} params")
                                console.print()
                        else:
                            console.print(f"[yellow]No tools found for {service}[/yellow]")
                    else:
                        console.print(f"[red]❌ Discovery failed: {result.get('error', 'Unknown error')}[/red]")
                        
                except Exception as e:
                    console.print(f"[red]❌ Error discovering tools: {str(e)}[/red]")
            else:
                console.print("[red]❌ Please specify a service name or use --all-services flag[/red]")
                console.print("Usage: discover-tools analysis-service")
                console.print("       discover-tools --all-services")
        
        asyncio.run(run_discovery())
        
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.option('--category', help='Filter tools by category')
@click.option('--service', help='Filter tools by service')
@click.pass_context
def list_discovered_tools(ctx, category, service):
    """List all previously discovered tools"""
    try:
        console = Console()
        console.print("\n[bold]📋 Discovered Tools Registry[/bold]")
        console.print("=" * 40)
        
        # This would ideally read from a persistent storage
        # For now, we'll show a placeholder
        console.print("[yellow]Tool registry not yet implemented.[/yellow]")
        console.print("Run 'discover-tools --all-services' first to populate the registry.")
        
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.argument('service_name', required=True)
@click.option('--tool-name', help='Test specific tool')
@click.pass_context
def test_discovered_tools(ctx, service_name, tool_name):
    """Test discovered tools for functionality"""
    try:
        console = Console()
        console.print(f"\n[bold]🧪 Testing Tools for {service_name}[/bold]")
        console.print("=" * 40)
        
        if tool_name:
            console.print(f"Testing specific tool: {tool_name}")
        else:
            console.print("Testing all discovered tools...")
        
        # This would test the actual tools
        console.print("[yellow]Tool testing not yet implemented.[/yellow]")
        console.print("This feature will validate discovered tools against their services.")
        
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


# ============================================================================
# ADVANCED MONITORING COMMANDS
# ============================================================================

@cli.command()
@click.pass_context
def view_dashboards(ctx):
    """List available monitoring dashboards"""
    try:
        monitoring_manager = cli_service.advanced_monitoring_manager
        asyncio.run(monitoring_manager.view_dashboards_from_cli())
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.pass_context
def view_alerts(ctx):
    """Show active monitoring alerts"""
    try:
        monitoring_manager = cli_service.advanced_monitoring_manager
        asyncio.run(monitoring_manager.view_alerts_from_cli())
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.pass_context
def view_slo_status(ctx):
    """Display SLO/SLA compliance status"""
    try:
        monitoring_manager = cli_service.advanced_monitoring_manager
        asyncio.run(monitoring_manager.view_slo_status_from_cli())
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")


@cli.command()
@click.pass_context
def view_metrics(ctx):
    """Show real-time system metrics"""
    try:
        monitoring_manager = cli_service.advanced_monitoring_manager
        asyncio.run(monitoring_manager.view_metrics_from_cli())
    except Exception as e:
        console = Console()
        console.print(f"[red]Error: {e}[/red]")

# ============================================================================
# END-TO-END WORKFLOW EXECUTION ASYNC FUNCTIONS
# ============================================================================

async def _execute_e2e_query_async(query, format, download, user_id, filename_prefix):
    """Execute end-to-end query processing with output generation."""
    console = Console()
    
    with console.status("[bold green]Processing query..."):
        try:
            # Call interpreter's execute-query endpoint
            request_data = {
                "query": query,
                "output_format": format,
                "user_id": user_id or "cli_user",
                "filename_prefix": filename_prefix
            }
            
            interpreter_url = "http://interpreter:5120"
            
            async with aiohttp.ClientSession() as session:
                async with session.post(f"{interpreter_url}/execute-query", json=request_data) as response:
                    result = await response.json()
            
            if result.get("status") == "completed":
                console.print(f"[green]✓[/green] Query executed successfully!")
                console.print(f"[cyan]Execution ID:[/cyan] {result.get('execution_id')}")
                console.print(f"[cyan]Workflow:[/cyan] {result.get('workflow_executed')}")
                
                output_info = result.get("output", {})
                if output_info:
                    console.print(f"[cyan]Output File:[/cyan] {output_info.get('filename')}")
                    console.print(f"[cyan]Format:[/cyan] {output_info.get('format')}")
                    console.print(f"[cyan]Size:[/cyan] {output_info.get('size_bytes')} bytes")
                    console.print(f"[cyan]Download URL:[/cyan] {output_info.get('download_url')}")
                    
                    if download and output_info.get('file_id'):
                        console.print("[yellow]Downloading file...[/yellow]")
                        await _download_output_async(output_info['file_id'], None)
                        
            elif result.get("status") == "failed":
                console.print(f"[red]✗[/red] Workflow execution failed: {result.get('error')}")
                
            elif result.get("status") == "no_workflow":
                console.print(f"[yellow]⚠[/yellow] {result.get('message')}")
                suggestions = result.get("suggestions", [])
                if suggestions:
                    console.print("[cyan]Suggestions:[/cyan]")
                    for suggestion in suggestions:
                        console.print(f"  • {suggestion}")
            else:
                console.print(f"[red]✗[/red] Error: {result.get('error', 'Unknown error')}")
                
        except Exception as e:
            console.print(f"[red]✗[/red] Error executing query: {str(e)}")


async def _execute_direct_workflow_async(name, parameters, format, download, user_id, filename_prefix):
    """Execute workflow directly with output generation."""
    console = Console()
    
    with console.status(f"[bold green]Executing {name} workflow..."):
        try:
            request_data = {
                "workflow_name": name,
                "parameters": parameters,
                "output_format": format,
                "user_id": user_id or "cli_user",
                "filename_prefix": filename_prefix
            }
            
            interpreter_url = "http://interpreter:5120"
            
            async with aiohttp.ClientSession() as session:
                async with session.post(f"{interpreter_url}/workflows/execute-direct", json=request_data) as response:
                    result = await response.json()
            
            if result.get("status") == "completed":
                console.print(f"[green]✓[/green] Workflow '{name}' executed successfully!")
                console.print(f"[cyan]Execution ID:[/cyan] {result.get('execution_id')}")
                
                output_info = result.get("output", {})
                if output_info:
                    console.print(f"[cyan]Output File:[/cyan] {output_info.get('filename')}")
                    console.print(f"[cyan]Format:[/cyan] {output_info.get('format')}")
                    console.print(f"[cyan]Size:[/cyan] {output_info.get('size_bytes')} bytes")
                    
                    if download and output_info.get('file_id'):
                        console.print("[yellow]Downloading file...[/yellow]")
                        await _download_output_async(output_info['file_id'], None)
                        
            else:
                console.print(f"[red]✗[/red] Workflow execution failed: {result.get('error')}")
                
        except Exception as e:
            console.print(f"[red]✗[/red] Error executing workflow: {str(e)}")


async def _download_output_async(file_id, save_path):
    """Download generated output file."""
    console = Console()
    
    try:
        interpreter_url = "http://interpreter:5000"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(f"{interpreter_url}/outputs/download/{file_id}") as response:
                if response.status == 200:
                    # Get filename from Content-Disposition header or use file_id
                    filename = file_id
                    if 'Content-Disposition' in response.headers:
                        disposition = response.headers['Content-Disposition']
                        if 'filename=' in disposition:
                            filename = disposition.split('filename=')[1].strip('"')
                    
                    # Determine save path
                    if save_path:
                        final_path = save_path
                    else:
                        final_path = f"./{filename}"
                    
                    # Download file
                    file_content = await response.read()
                    
                    with open(final_path, 'wb') as f:
                        f.write(file_content)
                    
                    console.print(f"[green]✓[/green] File downloaded: {final_path}")
                    console.print(f"[cyan]Size:[/cyan] {len(file_content)} bytes")
                    
                else:
                    error_text = await response.text()
                    console.print(f"[red]✗[/red] Download failed: {error_text}")
                    
    except Exception as e:
        console.print(f"[red]✗[/red] Error downloading file: {str(e)}")


async def _list_workflow_templates_async():
    """List available workflow templates."""
    console = Console()
    
    try:
        interpreter_url = "http://interpreter:5000"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(f"{interpreter_url}/workflows/templates") as response:
                result = await response.json()
        
        templates = result.get("templates", {})
        
        if templates:
            console.print(f"[green]Available Workflow Templates ({len(templates)})[/green]")
            console.print()
            
            table = Table(show_header=True, header_style="bold magenta")
            table.add_column("Name", style="cyan")
            table.add_column("Description", style="white")
            table.add_column("Services", style="yellow")
            table.add_column("Output Formats", style="green")
            
            for name, template in templates.items():
                services = ", ".join(template.get("services", []))
                output_types = ", ".join(template.get("output_types", []))
                table.add_row(
                    name,
                    template.get("description", ""),
                    services,
                    output_types
                )
            
            console.print(table)
        else:
            console.print("[yellow]No workflow templates available[/yellow]")
            
    except Exception as e:
        console.print(f"[red]✗[/red] Error fetching templates: {str(e)}")


async def _get_supported_formats_async():
    """Show supported output formats."""
    console = Console()
    
    try:
        interpreter_url = "http://interpreter:5000"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(f"{interpreter_url}/outputs/formats") as response:
                result = await response.json()
        
        formats = result.get("supported_formats", [])
        descriptions = result.get("format_descriptions", {})
        
        if formats:
            console.print("[green]Supported Output Formats[/green]")
            console.print()
            
            table = Table(show_header=True, header_style="bold magenta")
            table.add_column("Format", style="cyan")
            table.add_column("Description", style="white")
            
            for format_name in formats:
                description = descriptions.get(format_name, "No description available")
                table.add_row(format_name, description)
            
            console.print(table)
        else:
            console.print("[yellow]No supported formats found[/yellow]")
            
    except Exception as e:
        console.print(f"[red]✗[/red] Error fetching formats: {str(e)}")


async def _download_document_async(doc_id, save_path):
    """Download persistent document from doc_store."""
    console = Console()
    
    try:
        interpreter_url = "http://interpreter:5120"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(f"{interpreter_url}/documents/{doc_id}/download") as response:
                if response.status == 200:
                    # Get filename from Content-Disposition header or use doc_id
                    filename = doc_id
                    if 'Content-Disposition' in response.headers:
                        disposition = response.headers['Content-Disposition']
                        if 'filename=' in disposition:
                            filename = disposition.split('filename=')[1].strip('"')
                    
                    # Determine save path
                    if save_path:
                        final_path = save_path
                    else:
                        final_path = f"./{filename}"
                    
                    # Download file
                    file_content = await response.read()
                    
                    with open(final_path, 'wb') as f:
                        f.write(file_content)
                    
                    console.print(f"[green]✓[/green] Document downloaded: {final_path}")
                    console.print(f"[cyan]Document ID:[/cyan] {doc_id}")
                    console.print(f"[cyan]Size:[/cyan] {len(file_content)} bytes")
                    
                else:
                    error_data = await response.json()
                    console.print(f"[red]✗[/red] Download failed: {error_data.get('error', 'Unknown error')}")
                    
    except Exception as e:
        console.print(f"[red]✗[/red] Error downloading document: {str(e)}")


async def _get_document_provenance_async(doc_id):
    """Get comprehensive provenance for a workflow-generated document."""
    console = Console()
    
    try:
        interpreter_url = "http://interpreter:5120"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(f"{interpreter_url}/documents/{doc_id}/provenance") as response:
                result = await response.json()
        
        if result.get("error"):
            console.print(f"[red]✗[/red] Error: {result['error']}")
            return
        
        console.print(f"[green]Document Provenance: {doc_id}[/green]")
        console.print()
        
        # Document Info
        doc_info = result.get("document_info", {})
        console.print("[cyan]Document Information:[/cyan]")
        console.print(f"  • Title: {doc_info.get('title', 'N/A')}")
        console.print(f"  • Format: {doc_info.get('format', 'N/A')}")
        console.print(f"  • Created: {doc_info.get('created_at', 'N/A')}")
        console.print(f"  • Author: {doc_info.get('author', 'N/A')}")
        console.print()
        
        # Workflow Chain
        workflow_chain = result.get("workflow_chain", {})
        console.print("[cyan]Workflow Chain:[/cyan]")
        console.print(f"  • Services Used: {', '.join(workflow_chain.get('services_used', []))}")
        
        # Prompts Used
        prompts = workflow_chain.get("prompts_used", [])
        if prompts:
            console.print(f"  • Prompts Used: {len(prompts)}")
            for prompt in prompts[:3]:  # Show first 3
                console.print(f"    - {prompt.get('action', 'Unknown')} (Step {prompt.get('step_index', 'N/A')})")
        
        # Quality Metrics
        quality = workflow_chain.get("quality_metrics", {})
        if quality:
            console.print(f"  • Quality Score: {quality.get('confidence', 0):.2f}")
            console.print(f"  • Completeness: {quality.get('completeness', 0):.2f}")
        
        # Execution Metadata
        execution_metadata = result.get("execution_metadata", {})
        if execution_metadata:
            console.print()
            console.print("[cyan]Execution Details:[/cyan]")
            console.print(f"  • Execution ID: {execution_metadata.get('execution_id', 'N/A')}")
            console.print(f"  • Execution Time: {execution_metadata.get('execution_time', 'N/A')}")
            console.print(f"  • Generated At: {execution_metadata.get('generated_at', 'N/A')}")
            
    except Exception as e:
        console.print(f"[red]✗[/red] Error getting provenance: {str(e)}")


async def _list_workflow_documents_async(workflow_name, limit):
    """List all documents generated by a workflow."""
    console = Console()
    
    try:
        interpreter_url = "http://interpreter:5120"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(f"{interpreter_url}/documents/by-workflow/{workflow_name}", 
                                 params={"limit": limit}) as response:
                result = await response.json()
        
        documents = result.get("documents", [])
        
        if documents:
            console.print(f"[green]Documents for '{workflow_name}' workflow ({len(documents)} found)[/green]")
            console.print()
            
            table = Table(show_header=True, header_style="bold magenta")
            table.add_column("Document ID", style="cyan")
            table.add_column("Title", style="white")
            table.add_column("Format", style="yellow")
            table.add_column("Size", style="green")
            table.add_column("Created", style="blue")
            
            for doc in documents:
                size_kb = doc.get("size_bytes", 0) / 1024
                table.add_row(
                    doc.get("document_id", "N/A")[:12] + "...",
                    doc.get("title", "Untitled")[:40] + ("..." if len(doc.get("title", "")) > 40 else ""),
                    doc.get("format", "unknown"),
                    f"{size_kb:.1f} KB",
                    doc.get("created_at", "N/A")[:19] if doc.get("created_at") else "N/A"
                )
            
            console.print(table)
            console.print()
            console.print(f"[cyan]Use 'download-document --doc-id <ID>' to download any document[/cyan]")
        else:
            console.print(f"[yellow]No documents found for workflow '{workflow_name}'[/yellow]")
            
    except Exception as e:
        console.print(f"[red]✗[/red] Error listing documents: {str(e)}")


async def _get_execution_trace_async(execution_id):
    """Get detailed execution trace and generated documents."""
    console = Console()
    
    try:
        interpreter_url = "http://interpreter:5120"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(f"{interpreter_url}/workflows/{execution_id}/trace") as response:
                result = await response.json()
        
        if result.get("error"):
            console.print(f"[red]✗[/red] Error: {result['error']}")
            return
        
        console.print(f"[green]Execution Trace: {execution_id}[/green]")
        console.print()
        
        # Execution Details
        execution_details = result.get("execution_details", {})
        console.print("[cyan]Execution Details:[/cyan]")
        console.print(f"  • Workflow: {execution_details.get('workflow_name', 'N/A')}")
        console.print(f"  • Status: {execution_details.get('status', 'N/A')}")
        console.print(f"  • User: {execution_details.get('user_id', 'N/A')}")
        console.print(f"  • Started: {execution_details.get('started_at', 'N/A')}")
        console.print(f"  • Execution Time: {execution_details.get('execution_time', 'N/A')}")
        console.print()
        
        # Generated Documents
        documents = result.get("generated_documents", [])
        if documents:
            console.print(f"[cyan]Generated Documents ({len(documents)}):[/cyan]")
            
            for i, doc in enumerate(documents, 1):
                console.print(f"  {i}. {doc.get('title', 'Untitled')} ({doc.get('format', 'unknown')})")
                console.print(f"     ID: {doc.get('document_id', 'N/A')}")
                console.print(f"     Size: {doc.get('size_bytes', 0) / 1024:.1f} KB")
                console.print()
        else:
            console.print("[yellow]No documents generated by this execution[/yellow]")
            
    except Exception as e:
        console.print(f"[red]✗[/red] Error getting execution trace: {str(e)}")


if __name__ == "__main__":
    cli()
