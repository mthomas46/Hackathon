[tool:pytest]
# Test discovery and execution
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Parallel execution settings
addopts =
    --strict-markers
    --strict-config
    --disable-warnings
    --tb=short
    --asyncio-mode=auto
    -ra
    --maxfail=5
    --durations=10
    --durations-min=1.0

# Coverage settings
addopts_coverage =
    --cov=services.llm_gateway
    --cov-report=term-missing
    --cov-report=html:htmlcov
    --cov-report=xml
    --cov-fail-under=85

# Markers for test categorization
markers =
    unit: Unit tests (fast, isolated)
    integration: Integration tests (slower, with dependencies)
    slow: Slow tests (may take >30 seconds)
    provider: Tests that interact with LLM providers
    cache: Tests for caching functionality
    security: Tests for security features
    metrics: Tests for metrics collection
    parallel_safe: Tests safe for parallel execution
    serial_only: Tests that must run serially

# Test filtering
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::UserWarning
    error::RuntimeWarning

# Output formatting
console_output_style = progress
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(message)s (%(filename)s:%(lineno)s)
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Async test settings
asyncio_default_fixture_loop_scope = function

# xdist settings for parallel execution
looponfailroots =
    tests/unit/llm_gateway
    tests/integration/llm_gateway
